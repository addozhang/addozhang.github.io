<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>学习 on 乱世浮生</title><link>https://atbug.com/categories/%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 学习 on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 01 Jan 2018 12:30:55 +0000</lastBuildDate><atom:link href="https://atbug.com/categories/%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>Go In Action 读书笔记 四</title><link>https://atbug.com/go-in-action-four/</link><pubDate>Mon, 01 Jan 2018 12:30:55 +0000</pubDate><guid>https://atbug.com/go-in-action-four/</guid><description>
&lt;p>
&lt;div class="notices warning image-warning">
&lt;div class="label">Image not found&lt;/div>
&lt;style>
a.warning-link {
color: inherit !important;
font-weight: inherit !important;
text-decoration: underline !important;
border-bottom: none !important; }
&lt;/style>
&lt;p>网站链接: &lt;a href='https://talks.golang.org/2013/go4python/img/fib-go.png' title='在新选项卡中打开此网站链接' target='_blank' class='warning-link'>https://talks.golang.org/2013/go4python/img/fib-go.png&lt;/a>&lt;/p>
&lt;p>链接到文件: /static/https://talks.golang.org/2013/go4python/img/fib-go.png&lt;/p>
&lt;p>使用 &lt;a href='https://gohugo.io/content-management/page-bundles/' title='相关信息 Hugo Page Bundles' target='_blank' class='warning-link'>Page Bundles&lt;/a>: false&lt;/p>
&lt;/div>
&lt;/p>
&lt;h2 id="并发模式">并发模式&lt;/h2>
&lt;h3 id="runner">runner&lt;/h3>
&lt;p>runner展示了如何使用通道来监视程序的执行时间, 如果程序执行时间太长, 也可以用终止程序.
这个程序可用作corn作业执行&lt;/p></description></item><item><title>Go In Action 读书笔记 三</title><link>https://atbug.com/go-in-action-three/</link><pubDate>Mon, 01 Jan 2018 12:30:31 +0000</pubDate><guid>https://atbug.com/go-in-action-three/</guid><description>
&lt;h2 id="并发">并发&lt;/h2>
&lt;p>Go语言里的并发是指让某个函数可以独立于其他函数运行的能力. 当一个函数创建为goroutine时, Go会将其视为一个独立的工作单元. 这个工作单元会被调度到可用的&lt;strong>逻辑处理器&lt;/strong>上执行.&lt;/p>
&lt;p>Go的运行时调度器可以管理所有创建的goroutine, 并为其分配执行时间.
这个调度器在操作系统之上, 将操作系统的线程与逻辑处理器绑定, 并在逻辑处理器执行goroutine. &lt;strong>调度器可以在任何给定的时间, 全面控制哪个goroutine在哪个逻辑处理器上运行&lt;/strong>.&lt;/p>
&lt;p>Go的并发同步模型来自一个叫做通信顺序进程(Communicating Sequential Processes, &lt;a href="http://www.usingcsp.com">CSP&lt;/a>). CSP是一个消息传递模型, 通过在goroutine之前传递数据来传递消息, 不需要通过加锁实现同步访问. 用于在goroutine间传递消息的数据结构叫做通道(channel).&lt;/p>
&lt;h3 id="并发与并行">并发与并行&lt;/h3>
&lt;p>操作系统的线程(thread)和进程(process).&lt;/p>
&lt;p>进程类似应用程序在运行中需要用到和维护的各种资源的容器.
资源包括但不限于: 内存(来自文件系统的代码和数据), 句柄(文件, 设备, 操作系统), 线程.&lt;/p></description></item><item><title>Go In Action 读书笔记 二</title><link>https://atbug.com/go-in-action-two/</link><pubDate>Mon, 01 Jan 2018 12:28:04 +0000</pubDate><guid>https://atbug.com/go-in-action-two/</guid><description>
&lt;h2 id="go语言的类型系统">Go语言的类型系统&lt;/h2>
&lt;p>Go语言是静态类型的变成语言. 编译的时候需要确定类型.&lt;/p>
&lt;h3 id="用户定义的类型">用户定义的类型&lt;/h3>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="kd">type&lt;/span> &lt;span class="nx">user&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nx">name&lt;/span> &lt;span class="kt">string&lt;/span>
&lt;span class="nx">email&lt;/span> &lt;span class="kt">string&lt;/span>
&lt;span class="nx">ext&lt;/span> &lt;span class="kt">int&lt;/span>
&lt;span class="nx">privileged&lt;/span> &lt;span class="kt">bool&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>使用&lt;/strong>
零值和&lt;strong>结构字面量&lt;/strong>初始化&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="c1">//引用类型, 各个字段初始化为对应的零值
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="kd">var&lt;/span> &lt;span class="nx">bill&lt;/span> &lt;span class="nx">user&lt;/span> &lt;span class="err">#&lt;/span>&lt;span class="p">{&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="c1">//创建并初始化, 使用结构字面量
&lt;/span>&lt;span class="c1">&lt;/span>&lt;span class="nx">lisa&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">user&lt;/span>&lt;span class="p">{&lt;/span> &lt;span class="c1">//{Lisa lisa@email.com 123 true}
&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">name&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s">&amp;#34;Lisa&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nx">email&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s">&amp;#34;lisa@email.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nx">ext&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">123&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nx">privileged&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>结构字面量的赋值方式:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>不同行声明每一个字段和对应的值, 字段名和字段以&lt;code>:&lt;/code>分隔, 末尾以&lt;code>,&lt;/code>结尾&lt;/li>
&lt;li>不适用字段名, 只声明对应的值. 写在一行里, 以&lt;code>,&lt;/code>分隔, 结尾不需要&lt;code>,&lt;/code>. &lt;strong>要保证顺序&lt;/strong>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="nx">lisa&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s">&amp;#34;Lisa&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;lisa@email.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">123&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Go In Action 读书笔记 一</title><link>https://atbug.com/go-in-action-one/</link><pubDate>Mon, 01 Jan 2018 12:27:10 +0000</pubDate><guid>https://atbug.com/go-in-action-one/</guid><description>
&lt;p>
&lt;div class="notices warning image-warning">
&lt;div class="label">Image not found&lt;/div>
&lt;style>
a.warning-link {
color: inherit !important;
font-weight: inherit !important;
text-decoration: underline !important;
border-bottom: none !important; }
&lt;/style>
&lt;p>网站链接: &lt;a href='http://7xvxng.com1.z0.glb.clouddn.com/15142714785285.jpg' title='在新选项卡中打开此网站链接' target='_blank' class='warning-link'>http://7xvxng.com1.z0.glb.clouddn.com/15142714785285.jpg&lt;/a>&lt;/p>
&lt;p>链接到文件: /static/http://7xvxng.com1.z0.glb.clouddn.com/15142714785285.jpg&lt;/p>
&lt;p>使用 &lt;a href='https://gohugo.io/content-management/page-bundles/' title='相关信息 Hugo Page Bundles' target='_blank' class='warning-link'>Page Bundles&lt;/a>: false&lt;/p>
&lt;/div>
&lt;/p>
&lt;h2 id="关键字">关键字&lt;/h2>
&lt;h3 id="var">var&lt;/h3>
&lt;p>变量使用&lt;code>var&lt;/code>声明, 如果变量不是定义在任何一个函数作用域内, 这个变量就是包级变量.&lt;/p>
&lt;blockquote>
&lt;p>Go语言中, 所有变量都被初始化为其&lt;strong>零值&lt;/strong>. 对于数值类型, 其零值是&lt;strong>0&lt;/strong>; 对于字符串类型, 其零值是&lt;strong>空字符串&amp;quot;&amp;quot;&lt;/strong>; 对于布尔类型, 其零值是&lt;strong>false&lt;/strong>. 对于引用类型来说, 底层数据结构会被初始化对应的零值. 但是被生命被起零值的引用类型的变量, 会返回&lt;strong>nil&lt;/strong>作为其值.&lt;/p>
&lt;/blockquote>
&lt;h3 id="const">const&lt;/h3>
&lt;p>定义常量&lt;/p>
&lt;h3 id="interface">interface&lt;/h3>
&lt;p>声明接口&lt;/p>
&lt;h3 id="func">func&lt;/h3>
&lt;p>声明函数&lt;/p>
&lt;h3 id="defer">defer&lt;/h3>
&lt;p>安排后面的函数调用在当前函数返回时才执行.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="nx">file&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="nx">os&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;filePath&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">if&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">nil&lt;/span>
&lt;span class="k">return&lt;/span>
&lt;span class="k">defer&lt;/span> &lt;span class="nx">file&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nb">close&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="err">#&lt;/span> &lt;span class="nx">more&lt;/span> &lt;span class="nx">file&lt;/span> &lt;span class="nx">operation&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>SpringBoot源码 - 启动</title><link>https://atbug.com/glance-over-spring-boot-source/</link><pubDate>Fri, 08 Dec 2017 17:48:43 +0000</pubDate><guid>https://atbug.com/glance-over-spring-boot-source/</guid><description>
SpringBoot Application启动部分的源码阅读. SpringApplication 常用的SpringApplication.run(Class, Args)启动Spring应用, 创建或者更新ApplicationContext 静态方法run 使用source类实例化一个SpringApplication实例, 并调用实例方法run. public static ConfigurableApplicationContext run(Object[] sources, String[] args) { return new SpringApplication(sources).run(args); } 初始化initialize 实例化的时候首先通过尝试加载javax.servlet.Servlet和org.springframework.web.context.ConfigurableWebApplicationContext推断当前是否是web环境. 然后从spring.facto</description></item><item><title>Raft算法学习</title><link>https://atbug.com/learning-raft/</link><pubDate>Sat, 14 Oct 2017 05:57:34 +0000</pubDate><guid>https://atbug.com/learning-raft/</guid><description>
Raft 强一致性算法 名词 复制状态机 Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: http://wx4.sinaimg.cn/mw690/4858d6a8ly1fbxcex0w1fj20gt08vwfr.jpg 链接到文件: /static/http://wx4.sinaimg.cn/mw690/4858d6a8ly1fbxcex0w1fj20gt08vwfr.jpg 使用 Page Bundles: false 复制状态机是通过复制日志来实现的, 按照日志中的命令的顺序来执行这些命令. 相同的状态机执行相同的日志命令, 获得相同的执行结果. 任期号 (currentTerm) 每个成员都会保存一个任期号, 称为服务器最后知道的任期号. 投票的候选人id (votedFor) 当前任期内, 投票的候选人id, 即响应投票请求(见下文)返回true时的候选人id. 已被提交的最大日志条目的索引值 (commitIndex) 每个成员都会持有已被提交的最大日志条目的索引值 被状态机执行的最⼤日志条⽬的索引值 (lastApplied) 每个成员都会持有被状态机执行的最⼤日志条⽬的索引值 请求 日志复制请求 (AppendEntries RPC) 由领导人发送给其他服务器, 也</description></item><item><title>Kafka发送不同确认方式的性能差异</title><link>https://atbug.com/kafka-producer-acknowledge-benchmark/</link><pubDate>Tue, 10 Oct 2017 11:49:58 +0000</pubDate><guid>https://atbug.com/kafka-producer-acknowledge-benchmark/</guid><description>
背景 Kafka的性能众所周知，Producer支持acknowledge模式。即Kafka会想Producer返回消息发送的结果。但是在Java Client中，acknowledge的确认有两种：同步和异步。 同步是通过调用future.get()实现的；异步则是通过提供callback方法来实现。写了个简单的程序测试一下单线程中吞吐差异能有多大。注意这里只考虑横向对比。 发送端单线程 Kafka为单集群节点 topic的分区数为1 key长度1 payload长度100 测试工具 JMeter Kafka Meter future.get() + batch size =1 Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: http://7xvxng.com1.z0.glb.clouddn.com/15076056852541.jpg 链接到文件: /static/http://7xvxng.com1.z0.glb.clouddn.com/15076056852541.jpg 使用 Page Bundles: false future.get() + batch size = 16K Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important;</description></item><item><title>Kafka消息消费一致性</title><link>https://atbug.com/kafka-consumer-consistency/</link><pubDate>Tue, 26 Sep 2017 19:13:48 +0000</pubDate><guid>https://atbug.com/kafka-consumer-consistency/</guid><description>
Kafka消费端的offset主要由consumer来控制, Kafka降每个consumer所监听的tocpic的partition的offset保存在__consumer_offsets主题中. consumer需要将处理完成的消息的offset提交到服务端, 主要有ConsumerCoordinator完成的. 每次从kafka拉取数据之前, 假如是异步提交offset, 会先调用已经完成的offset commit的callBack, 然后检查ConsumerCoordinator的连接状态. 如果设置了自动提交offset, 会继续上次从服务端获取的数据的offset异步提交到服务端. 这里需要注意的是会</description></item><item><title>Kafka 恰好一次发送和事务消费示例</title><link>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging-example/</link><pubDate>Fri, 22 Sep 2017 18:03:43 +0000</pubDate><guid>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging-example/</guid><description>
核心思想 生产端一致性: 开启幂等和事务, 包含重试, 发送确认, 同一个连接的最大未确认请求数. 消费端一致性: 通过设置读已提交的数据和同时处理完成每一条消息之后手动提交offset. 生产端 public class ProducerTest { public static void main(String[] args) throws InterruptedException, ExecutionException { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &amp;#34;my-transactional-id&amp;#34;); props.put(ProducerConfig.ACKS_CONFIG, &amp;#34;all&amp;#34;); props.put(ProducerConfig.RETRIES_CONFIG, &amp;#34;3&amp;#34;); props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, &amp;#34;1&amp;#34;); Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props, new StringSerializer(), new StringSerializer()); producer.initTransactions(); try { producer.beginTransaction(); for (int i = 0; i &amp;lt; 5; i++) { Future&amp;lt;RecordMetadata&amp;gt; send = producer .send(new ProducerRecord&amp;lt;&amp;gt;(&amp;#34;my-topic&amp;#34;, Integer.toString(i), Integer.toString(i))); System.out.println(send.get().offset()); TimeUnit.MILLISECONDS.sleep(1000L); } producer.commitTransaction(); } catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) { // We can&amp;#39;t recover from these exceptions, so our only option is to close the producer and exit. producer.close(); } catch (KafkaException e) { // For all other exceptions, just abort the transaction and try again. producer.abortTransaction(); } producer.close(); } } 消费端 public class ConsumerTest { public static void main(String[] args) throws InterruptedException { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ConsumerConfig.GROUP_ID_CONFIG, &amp;#34;test&amp;#34;); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, OffsetResetStrategy.NONE.toString().toLowerCase(Locale.ROOT)); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &amp;#34;false&amp;#34;); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, &amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;); props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase(Locale.ROOT)); KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props); consumer.subscribe(Arrays.asList(&amp;#34;my-topic&amp;#34;)); while (true) { ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100); if (!records.isEmpty()) { for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records) { System.out.printf(&amp;#34;offset = %d, key = %s, value = %s%n&amp;#34;, record.offset(), record.key(), record.value()); //Manually commit each record consumer.commitSync(Collections.singletonMap(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1))); } } } } }</description></item><item><title>恰好一次发送和事务消息(译)</title><link>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging/</link><pubDate>Tue, 19 Sep 2017 19:13:26 +0000</pubDate><guid>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging/</guid><description>
Kafka提供“至少一次”交付语义, 这意味着发送的消息可以传送一次或多次. 人们真正想要的是“一次”语义,因为重复的消息没有被传递。 普遍地发声重复消息的情况有两种: 如果客户端尝试向集群发送消息并获取网络错误, 则重试可能会导致重复. 如果在发送消息之前发生网络错误, 则不会发生重复. 但是, 如果在将消息附加到日志之后发生网络错误, 但在将响应发送给发件人之前, 发件人将不知道发生了什么. 唯一的选择是重试和冒险重复或放弃并声明消息丢失。 如果客户端尝试向集群发送消息并获取网络错误, 则重试可能会导致重复. 如果在发送消息之前发生网络错误, 则不会发生重复. 但是, 如果在将消息附加到日志之后发生网络错误, 但在将响应发送给</description></item><item><title>Kafka Producer配置解读</title><link>https://atbug.com/kafka-producer-config/</link><pubDate>Tue, 19 Sep 2017 15:38:03 +0000</pubDate><guid>https://atbug.com/kafka-producer-config/</guid><description>
按照重要性分类, 基于版本0.11.0.0 高 bootstrap.servers 一组host和port用于初始化连接. 不管这里配置了多少台server, 都只是用作发现整个集群全部server信息. 这个配置不需要包含集群所有的机器信息. 但是最好多于一个, 以防服务器挂掉. key.serializer 用来序列化key的Serializer接口的实现类. value.serializer 用来序列化value的Serializer接口的实现类 acks producer希望leader返回的用于确认请求完成的确认数量. 可选值 all, -1, 0 1. 默认值为1 acks=0 不需要等待服务器的确认. 这是retries设置无效. 响应里来自服务端的offset总是-1. producer只管发不管发送成功与否。延迟低，容易丢失数据。 acks=1 表示le</description></item><item><title>JSON Patch</title><link>https://atbug.com/json-patch/</link><pubDate>Sun, 27 Aug 2017 14:41:44 +0000</pubDate><guid>https://atbug.com/json-patch/</guid><description>
JSON Path是在使用Kubernetes API的过程中首次使用的. 使用API做扩缩容的时候, 发送整个Deployment的全文不是个明智的做法, 虽然可行. 因此便使用了JSON Patch. JsonObject item = new JsonObject(); item.add(&amp;#34;op&amp;#34;, new JsonPrimitive(&amp;#34;replace&amp;#34;)); item.add(&amp;#34;path&amp;#34;, new JsonPrimitive(&amp;#34;/spec/replicas&amp;#34;)); item.add(&amp;#34;value&amp;#34;, new JsonPrimitive(instances)); JsonArray body = new JsonArray(); body.add(item); appsV1beta1Api.patchNamespacedScaleScale(id, namespace, body, null); fabric8s提供的kubernetes-client中使用的zjsonpatch则封装了JSON Patch操作. 例如在做扩缩容的时候或者当前的deployment, 修改replicas的值. 然后比较对象的不同(JsonDiff.asJson(sourceJsonNode, targetJsonNode)). 下面的内容部分翻译自JSON PATH, 有兴趣的可以跳转看原文. 什么是JSON Patch JSON Path是一直描述JSON文</description></item><item><title>如何在Openshift中使用hostPath</title><link>https://atbug.com/how-to-use-hostpath-in-openshift/</link><pubDate>Wed, 23 Aug 2017 19:29:51 +0000</pubDate><guid>https://atbug.com/how-to-use-hostpath-in-openshift/</guid><description>
使用openshift搭建的k8s的api创建Deployment，在启动的时候报下面的错误： Invalid value: &amp;ldquo;hostPath&amp;rdquo;: hostPath volumes are not allowed to be used] 解决方案： 一个方案是将user加入privileged scc中，另一个方案就是： oc edit scc restricted #添加下面这行 allowHostDirVolumePlugin: true</description></item><item><title>Kubernetes — 持久卷</title><link>https://atbug.com/kubernetes-persistent-volumes/</link><pubDate>Sun, 20 Aug 2017 22:25:40 +0000</pubDate><guid>https://atbug.com/kubernetes-persistent-volumes/</guid><description>
Persistent Volume 译自Persistent Volumes 介绍 管理存储是管理计算的独特问题。 PersistentVolume子系统为用户和管理员提供了一个API，其中提供了如何从如何使用存储提供存储的详细信息。为此，我们介绍两种新的API资源：PersistentVolume和PersistentVolumeClaim。 PersistentVolume（PV）是由管理员配置的集群中的一段存储。它是集群中的一种资源就像一个节点是一个集群的资源。 PV是类似Volumes的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。该API对象捕获存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 Persistent</description></item><item><title>暴力停止ExecutorService的线程</title><link>https://atbug.com/stop-a-thread-of-executor-service/</link><pubDate>Wed, 19 Jul 2017 22:25:19 +0000</pubDate><guid>https://atbug.com/stop-a-thread-of-executor-service/</guid><description>
停止，stop，这里说的是真的停止。如何优雅的结束，这里就不提了。 这里要用Thread.stop()。众所周知，stop()方法在JDK中是废弃的。 该方法天生是不安全的。使用thread.stop()停止一个线程，导致释放（解锁）所有该线程已经锁定的监视器（因沿堆栈向上传播的未检查异常ThreadDeath而解锁）。如果之前受这些监视器保护的任何对象处于不一致状态，则不一致状态的对象（受损对象）将对其他线程可见，这可能导致任意的行为。 有时候我们会有这种需求，不需要考虑线程执行到哪一步。一般这种情况是外部执行stop，比如执行业务的线程因为各种原因假死或者耗时较长，由于设计问题又无法响应优雅的停</description></item><item><title>私有构造函数捕获模式</title><link>https://atbug.com/private-constructor-capture-idiom/</link><pubDate>Wed, 24 May 2017 06:50:44 +0000</pubDate><guid>https://atbug.com/private-constructor-capture-idiom/</guid><description>
《Java并发编程实践》的注解中有提到这一概念。 The private constructor exists to avoid the race condition that would occur if the copy constructor were implemented as this (p.x, p.y); this is an example of the private constructor capture idiom (Bloch and Gafter, 2005). 结合原文代码： @ThreadSafe public class SafePoint{ @GuardedBy(&amp;#34;this&amp;#34;) private int x,y; private SafePoint (int [] a) { this (a[0], a[1]); } public SafePoint(SafePoint p) { this (p.get()); } public SafePoint(int x, int y){ this.x = x; this.y = y; } public synchronized int[] get(){ return new int[] {x,y}; } public synchronized void set(int x, int y){ this.x = x; this.y = y; } } 这里的构造器public SafePoint(SafePoint p) { this (p.get()); }是为了捕获另一个实例的状态。get()方法是一个同步方法，为了避免竞态没有分别提供x、y的公有getter方法。 为了保证SafePoint的多线程安全性，在使用另一个实例构造新的实例时，使用了一个私有的构造器。 首先为什么不用下面这种，还是为了避免竞态（p.x和p.y调用不是原子操作）。 public SafePoint(SafePoint p) { this(p.x, p.y) } 同理，这</description></item><item><title>Docker快速构建Cassandra和Java操作</title><link>https://atbug.com/java-operate-cassandra-deployed-in-docker/</link><pubDate>Thu, 18 May 2017 23:33:24 +0000</pubDate><guid>https://atbug.com/java-operate-cassandra-deployed-in-docker/</guid><description>
搭建Cassandra 使用docker创建Cassandra，方便快捷 docker pull cassandra:latest docker run -d --name cassandra -p 9042:9042 cassandra docker exec -it cassandra bash 创建keyspace、table #cqlsh&amp;gt;#createkeyspaceCREATEKEYSPACEcontactsWITHREPLICATION={&amp;#39;class&amp;#39;:&amp;#39;SimpleStrategy&amp;#39;,&amp;#39;replication_factor&amp;#39;:1};#useUSEcontacts;#createtableCREATETABLEcontact(idUUID,emailTEXTPRIMARYKEY);查看表数据 cqlsh:contacts&amp;gt; SELECT * FROM contact; email | id -------+---- (0 rows) Java客</description></item><item><title>从零开始用docker运行spring boot应用</title><link>https://atbug.com/run-spring-boot-app-in-docker/</link><pubDate>Thu, 20 Apr 2017 21:58:42 +0000</pubDate><guid>https://atbug.com/run-spring-boot-app-in-docker/</guid><description>
假设已经安装好Docker Springboot应用 pom添加依赖和构建插件 &amp;lt;parent&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.5.3.RELEASE&amp;lt;/version&amp;gt; &amp;lt;/parent&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;/plugin&amp;gt; &amp;lt;/plugins&amp;gt; &amp;lt;/build&amp;gt; 应用代码 package com.atbug.spring.boot.test; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * Created by addo on 2017/5/15. */ @SpringBootApplication @RestController public class Application { @RequestMapping(&amp;#34;/&amp;#34;) public String home(){ return &amp;#34;Hello world!&amp;#34;; } public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 应用构建 mvn clean package Centos 7 with Java8 获取Centos7 镜像 docker pull centos:7 准备centos-java8的dockerfile FROM centos:7 MAINTAINER Addo Zhang &amp;#34;duwasai@gmail.com&amp;#34; # Set correct environment variables. ENV HOME /root ENV LANG en_US.UTF-8 ENV LC_ALL en_US.UTF-8 RUN yum install -y curl; yum upgrade -y; yum update -y; yum clean all ENV JDK_VERSION 8u11 ENV JDK_BUILD_VERSION b12 RUN curl -LO &amp;#34;http://download.oracle.com/otn-pub/java/jdk/$JDK_VERSION-$JDK_BUILD_VERSION/jdk-$JDK_VERSION-linux-x64.rpm&amp;#34; -H &amp;#39;Cookie: oraclelicense=accept-securebackup-cookie&amp;#39; &amp;amp;&amp;amp; rpm -i jdk-$JDK_VERSION-linux-x64.rpm; rm -f jdk-$JDK_VERSION-linux-x64.rpm; yum clean all ENV JAVA_HOME /usr/java/default RUN yum remove curl; yum clean all 创建centos-java8镜像 docker build -t addo/centos-java8 . Docker中运行应用 准备应用镜像的dockerfile FROM addo/centos-java8 ADD target/boot-test-1.0-SNAPSHOT.jar /opt/app.jar EXPOSE 8080 CMD java -jar /opt/app.jar 构建应用镜像 docker build -t temp/spring-boot-app . 运行 docker run --name spring-boot-app</description></item><item><title>Jasig CAS Web and Proxy flow</title><link>https://atbug.com/jasig-cas-web-and-proxy-flow/</link><pubDate>Tue, 18 Apr 2017 10:36:16 +0000</pubDate><guid>https://atbug.com/jasig-cas-web-and-proxy-flow/</guid><description>
最近因为需求在看CAS相关的只是，由于需要后端调用，用到proxy（代理）模式。整理了下web flow和proxy web flow的流程。 Web Flow Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/CAS-Service-Ticket.jpg 链接到文件: /static//media/CAS-Service-Ticket.jpg 使用 Page Bundles: false Proxy Web Flow Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/CAS-Proxy-Ticket.jpg 链接到文件: /static//media/CAS-Proxy-Ticket.jpg 使用 Page Bundles: false</description></item><item><title>一个Tomcat类加载问题</title><link>https://atbug.com/one-tomcat-class-load-issue/</link><pubDate>Wed, 12 Apr 2017 10:40:01 +0000</pubDate><guid>https://atbug.com/one-tomcat-class-load-issue/</guid><description>
背景 一个Tomcat实例中运行了三个应用，其中一个对接了Apereo的CAS系统。现在要求另外两个系统也对接CAS系统，问题就出现了： 应用启动后打开其中两个应用的任何一个，登录完成后系统都没有问题。唯独首选打开第三个，其他两个报错ClassNotFoundException: org.apache.xerces.parsers.SAXParser。 发现这个类来自xerces:xercesImpl:jar:2.6.2，使用mvn dependency:tree发现是被xom:xom:1.1简洁引用。 分析 CAS client jar中使用XMLReaderFactory创建XMLReader，首次创建会从classpa</description></item><item><title>GreenPlum JDBC和C3P0数据源</title><link>https://atbug.com/greenplum-jdbc-and-c3p0-datasource/</link><pubDate>Mon, 10 Apr 2017 08:29:00 +0000</pubDate><guid>https://atbug.com/greenplum-jdbc-and-c3p0-datasource/</guid><description>
在网上搜索GreenPlum（GPDB）的数据源配置的时候，发现搜索结果都是用postgresql的配置。 import com.mchange.v2.c3p0.DataSources; import javax.sql.DataSource; import java.sql.*; import java.util.Properties; /** * Created by addo on 2017/4/10. */ public class JDBCTest { private static String POSTGRESQL_URL = &amp;#34;jdbc:postgresql://192.168.56.101:5432/example&amp;#34;; private static String POSTGRESQL_USERNAME = &amp;#34;dbuser&amp;#34;; private static String POSTGRESQL_PASSWORD = &amp;#34;password&amp;#34;; private static String GPDB_URL = &amp;#34;jdbc:pivotal:greenplum://192.168.56.101:5432;DatabaseName=test&amp;#34;; private static String GPDB_USERNAME = &amp;#34;dbuser&amp;#34;; private static String GPDB_PASSWORD = &amp;#34;password&amp;#34;; /** * Postgresql Connection * * @return * @throws ClassNotFoundException * @throws SQLException */ public static Connection postgresqlConnection() throws ClassNotFoundException, SQLException { Class.forName(&amp;#34;org.postgresql.Driver&amp;#34;); return DriverManager.getConnection(POSTGRESQL_URL, POSTGRESQL_USERNAME, POSTGRESQL_PASSWORD); } /** * GreenPlum Connection * * @return * @throws ClassNotFoundException * @throws SQLException */ public static Connection gpdbConnection() throws ClassNotFoundException, SQLException { Class.forName(&amp;#34;com.pivotal.jdbc.GreenplumDriver&amp;#34;); return DriverManager.getConnection(GPDB_URL, GPDB_USERNAME, GPDB_PASSWORD); } /** * GreenPlud C3P0 Datasource Connection * * @return * @throws SQLException */ public static Connection gpdbC3P0Connection() throws SQLException { Properties c3p0Props = new Properties(); c3p0Props.setProperty(&amp;#34;driverClass&amp;#34;, &amp;#34;com.pivotal.jdbc.GreenplumDriver&amp;#34;); c3p0Props.setProperty(&amp;#34;jdbcUrl&amp;#34;, GPDB_URL); c3p0Props.setProperty(&amp;#34;user&amp;#34;, GPDB_USERNAME); c3p0Props.setProperty(&amp;#34;password&amp;#34;, GPDB_PASSWORD); c3p0Props.setProperty(&amp;#34;acquireIncrement&amp;#34;, &amp;#34;5&amp;#34;); c3p0Props.setProperty(&amp;#34;initialPoolSize1&amp;#34;, &amp;#34;1&amp;#34;); c3p0Props.setProperty(&amp;#34;maxIdleTime&amp;#34;, &amp;#34;60&amp;#34;); c3p0Props.setProperty(&amp;#34;maxPoolSize&amp;#34;, &amp;#34;50&amp;#34;); c3p0Props.setProperty(&amp;#34;minPoolSize&amp;#34;, &amp;#34;1&amp;#34;); c3p0Props.setProperty(&amp;#34;idleConnectionTestPeriod&amp;#34;, &amp;#34;60&amp;#34;); return DataSources.unpooledDataSource(GPDB_URL, c3p0Props).getConnection(); } public static void main(String[] args) throws ClassNotFoundException, SQLException { Connection[] connections = new Connection[]{postgresqlConnection(), gpdbConnection(), gpdbC3P0Connection()}; for (Connection connection : connections) { CallableStatement callableStatement = connection.prepareCall(&amp;#34;select * from user&amp;#34;); boolean execute = callableStatement.execute(); ResultSet resultSet = callableStatement.getResultSet(); while (resultSet.next()) { System.out.println(resultSet.getString(&amp;#34;current_user&amp;#34;)); } callableStatement.close(); connection.close(); } } } 源代码</description></item><item><title>Scala笔记：def VS val</title><link>https://atbug.com/def-vs-val-in-scala/</link><pubDate>Sun, 09 Apr 2017 08:24:40 +0000</pubDate><guid>https://atbug.com/def-vs-val-in-scala/</guid><description>
先说原理： val修饰的在定义的时候执行 def修饰的在调用的时候执行 直观的例子： //注释的行为REPL输出 def test: () =&amp;gt; Int = { println(&amp;#34;def called&amp;#34;) val r = util.Random.nextInt () =&amp;gt; r } //test: () =&amp;gt; Int test() //def called //res82: Int = -950077410 test() //def called //res83: Int = 1027028032 val test: () =&amp;gt; Int = { println(&amp;#34;def called&amp;#34;) val r = util.Random.nextInt () =&amp;gt; r } //def called //test: () =&amp;gt; Int = $$Lambda$1382/338526071@42f2515d test() //res84: Int = 300588352 test() //res84: Int = 300588352 def在方法定义的时候除了新的方法没有任何输出；之后每次调用的时候都会执行一次，而且是每次调用都获得一个新的方法（random值不同） val在方法定义的时候除了新的方法，还会执行并获得一个方法；之后每次调用都只是执行了定义的时候获得的方法（() =&amp;gt; r，r值固定） 进阶 def timer[A](f: =&amp;gt; A) = { def now = System.currentTimeMillis val start = now; val a = f; val end = now println(s&amp;#34;Executed int ${end - start}ms&amp;#34;) a } val veryRandomAmount = timer { util.Random.setSeed(System.currentTimeMillis) for (i &amp;lt;- 1 to 100000) util.Random.nextDouble util.Random.nextDouble } 看过</description></item><item><title>Centos编译安装Redis</title><link>https://atbug.com/install-redis-on-centos/</link><pubDate>Fri, 07 Apr 2017 16:48:46 +0000</pubDate><guid>https://atbug.com/install-redis-on-centos/</guid><description>
版本 Centos7 Redis3.2.8 编译安装 wget http://download.redis.io/releases/redis-3.2.8.tar.gz tar -zxvf redis-3.2.8.tar.gz cd redis-3.2.8 sudo make test sudo make install 启动 redis-server 问题 /bin/sh: cc: command not found **原因：**Centos安装时选择的类型是Infrastructure，没有c++的编译工具。 解决：sudo yum -y install gcc gcc-c++ libstdc++-devel malloc.h:50:31: fatal error: jemalloc/jemalloc.h: No such file or directory **原因：**Redis使用的默认的memory allocator是libc，而Linux系统中默认的是jemalloc，需要制动MALLOC变量。 解决：sudo make MALLOC=libc install</description></item><item><title>Centos上安装Postgresql</title><link>https://atbug.com/install-postgresql-on-centos/</link><pubDate>Thu, 06 Apr 2017 22:54:17 +0000</pubDate><guid>https://atbug.com/install-postgresql-on-centos/</guid><description>
版本 Centos7 Postgresql9.2 Enable ssh service sshd start Open firewall for 22 firewall-cmd —state firewall-cmd —list-all firewall-cmd —permanent —zone=public —add-port=22/tcp firewall-cmd —reload Install Postgresql yum install postgres su postgres postgres —version 默认会创建postgres:postgres用户和组 切换用户 su - postgres 初始化数据库 通过指定数据文件目录初始化db initdb -D /var/lib/pgsql/data 修改端口防火墙 默认端口是5432，需要在防火墙中打开端口 firewall-cmd &amp;ndash;permanent &amp;ndash;zone=public &amp;ndash;add-port=5432/tcp 修改监听的ip 需要外部访问的话，需要修改postgresql.conf中的监听ip，&amp;lsquo;0.0.0.0&amp;rsquo;允许所有ipv4的ip访问，''::&amp;lsquo;&amp;lsquo;允许所有ipv6的ip访问 listen_addresses = &amp;ldquo;0.0.0.0&amp;rdquo; 修改需要重启p</description></item><item><title>Key长度对Redis性能影响</title><link>https://atbug.com/redis-performance-key-length/</link><pubDate>Thu, 16 Mar 2017 10:37:03 +0000</pubDate><guid>https://atbug.com/redis-performance-key-length/</guid><description>
最近Redis的使用中用的到key可能比较长，但是Redis的官方文档没提到key长度对性能的影响，故简单做了个测试。 环境 Redis和测试程序都是运行在本地，不看单次的性能，只看不同的长度堆读写性能的影响。 测试方法 使用长度分别为10, 100, 500, 1000, 2500, 5000, 7500, 10,000, and 20,000的key，value长度1000，读写1000次。 结果 Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/14896309668401.jpg 链接到文件: /static//media/14896309668401.jpg 使用 Page Bundles: false Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/14896309585857.jpg 链接到文件: /static//media/14896309585857.jpg 使用 Page Bundles: false 从结果来看随着长度的增加，读写的耗时都随之增加。 长度为10：写平均耗时0.053ms，读0.040ms 长度为20000：写平均耗时0.352</description></item><item><title>遍历Collection时删除元素</title><link>https://atbug.com/remove-element-while-looping-collection/</link><pubDate>Sun, 05 Mar 2017 22:04:58 +0000</pubDate><guid>https://atbug.com/remove-element-while-looping-collection/</guid><description>
其实标题我想用《为什么foreach边循环边移除元素要用Iterator？》可是太长。 不用Iterator，用Collection.remove()，会报ConcurrentModificationException错误。 for(Integer i : list) { list.remove(i); //Throw ConcurrentModificationException } 其实使用foreach的时候，会自动生成一个Iterator来遍历list。不只是remove，使用add、clear等方法一样会出错。 拿ArrayList来说，它有一个私有的Iterator接口的内部类Itr： private class Itr implements Iterator&amp;lt;E&amp;gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; //sevrval methods } 使用Iterator来遍历ArrayList实际上是通过两个指针来遍历Arr</description></item><item><title>Java Volatile关键字</title><link>https://atbug.com/deep-in-java-volatile-keywork/</link><pubDate>Thu, 02 Mar 2017 08:30:29 +0000</pubDate><guid>https://atbug.com/deep-in-java-volatile-keywork/</guid><description>
volatile通过保证对变量的读或写都是直接从内存中读取或直接写入内存中，保证了可见性；但是volatile并不足以保证线程安全，因为无法保证原子性，如count++操作： 将值从内存读入寄存器中 进行加1操作，内存保存到寄存器中 结果从寄存器flush到内存中 借用一张图来看： Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: http://tutorials.jenkov.com/images/java-concurrency/java-volatile-2.png 链接到文件: /static/http://tutorials.jenkov.com/images/java-concurrency/java-volatile-2.png 使用 Page Bundles: false 不是volatile的变量的指令执行顺序是1-&amp;gt;2-&amp;gt;3；而声明为volatile的变量，顺序是1-&amp;gt;23。从这里看，volatile保证了一个线程修改了volatile修饰的变量，变化会马上体现在内存中。线程间看到的值是一样的。 上面说</description></item><item><title>Haproxy虚拟主机SSL</title><link>https://atbug.com/haproxy-multi-host-with-ssl/</link><pubDate>Mon, 27 Feb 2017 19:31:53 +0000</pubDate><guid>https://atbug.com/haproxy-multi-host-with-ssl/</guid><description>
Haproxy为多个域名配置SSL 生成自签名证书 sudo mkdir /etc/ssl/atbug.com sudo openssl genrsa -out /etc/ssl/atbug.com/atbug.com.key 1024 sudo openssl req -new -key /etc/ssl/atbug.com/atbug.com.key -out /etc/ssl/atbug.com/atbug.com.csr sudo openssl x509 -req -days 365 -in /etc/ssl/atbug.com/atbug.com.csr -singkey /etc/ssl/atbug.com/atbug.com.key -out /etc/ssl/atbug.com/atbug.com.crt sudo openssl x509 -req -days 365 -in /etc/ssl/atbug.com/atbug.com.csr -signkey /etc/ssl/atbug.com/atbug.com.key -out /etc/ssl/atbug.com/atbug.com.crt sudo cat /etc/ssl/atbug.com/atbug.com.crt /etc/ssl/atbug.com/atbug.com.key | sudo tee /etc/ssl/atbug.com/atbug.com.pem Haproxy配置 frontend https bind *:443 ssl crt /etc/ssl/atbug.com/atbug.com.pem option tcplog mode http #option forwardfor ###atbug-https acl atbug-https hdr_beg(host) -i test.atbug.com use_backend rome-atbug-https-backend if atbug-https backend rome-atbug-https-backend balance roundrobin mode http option ssl-hello-chk server node-1 ip:port cookie dw2-vm-test-apps003 check inter 2000 rise 3 fall 3 weight 50</description></item><item><title>mybatis报错“Result Maps collection already contains value for ***”</title><link>https://atbug.com/duplicate-resultmap-in-mybatis-mapper/</link><pubDate>Wed, 22 Feb 2017 14:12:18 +0000</pubDate><guid>https://atbug.com/duplicate-resultmap-in-mybatis-mapper/</guid><description>
这是工作中遇到的一个问题：测试环境部署出错，报了下面的问题。 Caused by: java.lang.IllegalArgumentException: Result Maps collection already contains value for xxx.xxx.xxxRepository.BaseResultMap at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:802) at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:774) at org.apache.ibatis.session.Configuration.addResultMap(Configuration.java:556) at org.apache.ibatis.builder.MapperBuilderAssistant.addResultMap(MapperBuilderAssistant.java:217) at org.apache.ibatis.builder.ResultMapResolver.resolve(ResultMapResolver.java:47) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:285) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:252) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElements(XMLMapperBuilder.java:244) at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:116) 检查了对应的mapper文件和java文件，已经8个多月没有修改过了。也检查了内容，没有发现重复的BaseResultMap；select中也resultMap的引用也都正确。 其实到最后发现跟代码一丁点关系都没有，是部署的时候没有删除旧版本的代码导致两个不同版本的jar同时存在，相应的mapper文件也有两个。 看了下源码，mybatis在创建SessionFactoryBean解析xml时候，会把xml中的resultMap放入到一个HashMap的子类StrictMap中，k</description></item><item><title>消费时offset被重置导致重复消费</title><link>https://atbug.com/offset-be-reset-when-consuming/</link><pubDate>Mon, 20 Feb 2017 13:23:49 +0000</pubDate><guid>https://atbug.com/offset-be-reset-when-consuming/</guid><description>
这是实际使用时遇到的问题：kafka api的版本是0.10，发现有重复消费问题；检查log后发现在commit offset的时候发生超时。 Auto offset commit failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records. 15:12:12.364 [main] WARN o.a.k.c.c.i.ConsumerCoordinator - Auto offset commit failed for group test: Commit offsets failed with retriable exception. You should retry committing offsets. 看了Kafka的API文档，发现0.10中提供了新的配置max.poll.records： The maximum number of records returned in a single call to poll(). type: int default: 2147483647 如果生产端写入很快，消费端处理耗时。一个batch的处理时间大于session.timeout.ms，会导致session time out，引起of</description></item><item><title>TheadPoolExecutor源码分析</title><link>https://atbug.com/threadpoolexecutor-sourcecode-analysis/</link><pubDate>Mon, 20 Feb 2017 09:56:07 +0000</pubDate><guid>https://atbug.com/threadpoolexecutor-sourcecode-analysis/</guid><description>
TheadPoolExecutor源码分析 ThreadPoolExecutor是多线程中经常用到的类，其使用一个线程池执行提交的任务。 实现 没有特殊需求的情况下，通常都是用Executors类的静态方法如newCachedThreadPoll来初始化ThreadPoolExecutor实例： public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;()); } 从Executors的方法实现中看出，BlockingQueue使用的SynchronousQueue，底层使用了栈的实现。值得注意的是，这个SynchronousQueue是没有容量限制的，Executors也将maximumPoolSize设为Integer.MAX_VALUE</description></item><item><title>Kafka Java生产者模型</title><link>https://atbug.com/kafka-java-producer-model/</link><pubDate>Wed, 04 Jan 2017 16:33:02 +0000</pubDate><guid>https://atbug.com/kafka-java-producer-model/</guid><description>
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/14835174309242.jpg 链接到文件: /static//media/14835174309242.jpg 使用 Page Bundles: false Producer初始化 初始化KafkaProducer实例，同时通过Config数据初始化MetaData、NetWorkClient、Accumulator和Sender线程。启动Sender线程。 MetaData信息 记录Cluster的相关信息，第一次链接使用Config设置，之后会从远端poll信息回来，比如host.name等信息。 Accumulator实例 Accumulator持有一个Map实例，key为TopicPartition（封装了topic和partition信息）对象，Value为RecordBatc</description></item><item><title>Flume - FileChannel （一）</title><link>https://atbug.com/flume-filechannel-overview/</link><pubDate>Wed, 23 Nov 2016 09:23:57 +0000</pubDate><guid>https://atbug.com/flume-filechannel-overview/</guid><description>
概述 当使用Flume的时候，每个流程都包含了输入源、通道和输出。一个典型的例子是一个web服务器将事件通过RPC（搬入AvroSource）写入输入源中，输入源将其写入MemoryChannel，最后HDFS Sink消费事件将其写入HDFS中。 Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: http://blog.cloudera.com//wp-content/uploads/2012/09/flume1.png 链接到文件: /static/http://blog.cloudera.com//wp-content/uploads/2012/09/flume1.png 使用 Page Bundles: false MemeoryChannel提供了高吞吐量但是在系统崩溃或者断电时会丢失数据。因此需要开发一个可持久话通道。FileChannel是在FLUME-1085里实现的。目标是提供一个高可用高吞吐量的通道。FileChannle保证了在失误提交之后，在崩溃或者断电后不丢失数据。 需要注意的是</description></item><item><title>探索Rabbitmq的Java客户端</title><link>https://atbug.com/deep-in-rabbitmq-java-client/</link><pubDate>Sun, 09 Oct 2016 09:20:07 +0000</pubDate><guid>https://atbug.com/deep-in-rabbitmq-java-client/</guid><description>
AMQPConnection 实例初始化 创建Connection时会通过FrameHandlerFacotry创建一个SocketFrameHandler，SocketFrameHandler对Socket进行了封装。 public AMQConnection(ConnectionParams params, FrameHandler frameHandler) { checkPreconditions(); this.username = params.getUsername(); this.password = params.getPassword(); this._frameHandler = frameHandler; this._virtualHost = params.getVirtualHost(); this._exceptionHandler = params.getExceptionHandler(); this._clientProperties = new HashMap&amp;lt;String, Object&amp;gt;(params.getClientProperties()); this.requestedFrameMax = params.getRequestedFrameMax(); this.requestedChannelMax = params.getRequestedChannelMax(); this.requestedHeartbeat = params.getRequestedHeartbeat(); this.shutdownTimeout = params.getShutdownTimeout(); this.saslConfig = params.getSaslConfig(); this.executor = params.getExecutor(); this.threadFactory = params.getThreadFactory(); this._channelManager = null; this._brokerInitiatedShutdown = false; this._inConnectionNegotiation = true; // we start out waiting for the first protocol response } 启动连接 初始化WorkService和HeartBeatSender。 创建一个channel0的AMQChannel，这个channel不会被ChannelManager管理。 首先channel0会将一个BlockingRpcContinuation作为当前未完成的Rpc请</description></item><item><title>Git回车换行</title><link>https://atbug.com/crlf-in-git/</link><pubDate>Wed, 14 Sep 2016 09:16:10 +0000</pubDate><guid>https://atbug.com/crlf-in-git/</guid><description>
最近又个项目，checkout之后，没做任何改动前git status发现已经有modified了，通过git diff发现有两种改动： - warning: CRLF will be replaced by LF in ** - 删除并添加的同样的行 使用git diff -w却没有改动；使用git diff –ws-error-highlight=new,old发现行尾有**^M** 我本人用的是Linux，其他同事有用Windows，问题就出在平台上。 Windows用CR LF来定义换行，Linux用LF。CR全称是Carriage Return ,或者表示为\r, 意思是回车。 LF全称是Line Feed，它才是真正意义上的换行表示符。 git config中关于CRLF有两个设定：core.autocrlf和c</description></item><item><title>深入剖析HashSet和HashMap实现</title><link>https://atbug.com/deep-in-implementation-of-hashset/</link><pubDate>Mon, 11 Jul 2016 14:57:16 +0000</pubDate><guid>https://atbug.com/deep-in-implementation-of-hashset/</guid><description>
HashSet是一个包含非重复元素的集合，如何实现的，要从底层实现代码看起。 背景 首先非重复元素如何定义，看Set的描述： More formally, sets contain no pair of elements e1 and e2 such that e1.equals(e2), and at most one null element. Set不会找到两个元素，并且两个元素满足e1.equals(e2)为true；并且最多只有一个null元素。 如果没有重写equals方法，查看Object类中equal方法的实现，==比较的其实是两个对象在内存中的地址。 public boolean equals(Object obj) { return (this == obj); } 说起equals方法，就不得不说hashCode方法了。Java中对于hashCode有个常规协定 The general contract of hashCode is: Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. This integer need not remain consistent</description></item><item><title>多线程下的单例模式+反汇编</title><link>https://atbug.com/singleton-in-multi-threads-programming/</link><pubDate>Wed, 06 Jul 2016 16:57:09 +0000</pubDate><guid>https://atbug.com/singleton-in-multi-threads-programming/</guid><description>
多线程下的单例模式的实现，顺便做了反汇编。 public class MySingleton { private static MySingleton INSTANCE; private MySingleton() { } public static MySingleton getInstance() { if (INSTANCE == null) { synchronized (MySingleton.class) { INSTANCE = new MySingleton(); } } return INSTANCE; } } Compiled from &amp;#34;MySingleton.java&amp;#34; public class MySingleton { public static MySingleton getInstance(); Code: 0: getstatic #2 // Field INSTANCE:LMySingleton; //+获得类的指定域，并压入栈顶 3: ifnonnull 32 //+不为null时跳转到行号32 6: ldc_w #3 // class MySingleton //+常量值从常量池中推送至栈顶（宽索引），推送的为地址 9: dup //+复制栈顶数值，并且复制值进栈 10: astore_0 //+将栈顶数值（objectref）存入当前 frame的局部变量数组中指定下标(index）处的变量中，栈顶数值出栈。这里存的是MySingleton类定义的地址 11: monitorenter //+获得对象锁即MySingleton地址 12: new #3 // class MySingleton //+创建一个对象，并且其引用进栈 15: dup //+复</description></item><item><title>使用Kryo替换spring amqp的Java序列化</title><link>https://atbug.com/use-kryo-in-spring-amqp-serialization/</link><pubDate>Wed, 29 Jun 2016 05:29:14 +0000</pubDate><guid>https://atbug.com/use-kryo-in-spring-amqp-serialization/</guid><description>
spring amqp的原生并没有对Kryo加以支持，Kryo的优点就不多说了。 git地址：https://github.com/addozhang/spring-kryo-messaeg-converter public class KryoMessageConverter extends AbstractMessageConverter { public static final String CONTENT_TYPE = &amp;#34;application/x-kryo&amp;#34;; public static final String DEFAULT_CHARSET = &amp;#34;UTF-8&amp;#34;; private String defaultCharset = DEFAULT_CHARSET; private KryoFactory kryoFactory = new DefaultKryoFactory(); /** * Crate a message from the payload object and message properties provided. The message id will be added to the * properties if necessary later. * * @param object the payload * @param messageProperties the message properties (headers) * @return a message */ @Override protected Message createMessage(Object object, MessageProperties messageProperties) { byte[] bytes = null; Kryo kryo = kryoFactory.create(); Output output = new ByteBufferOutput(4096, 1024 * 1024); try { kryo.writeClassAndObject(output, object); bytes = output.toBytes(); } finally { output.close(); } messageProperties.setContentType(CONTENT_TYPE); if (messageProperties.getContentEncoding() == null) { messageProperties.setContentEncoding(defaultCharset); } return new Message(bytes, messageProperties); } @Override public Object fromMessage(Message message) throws MessageConversionException { Object content = null; MessageProperties properties = message.getMessageProperties(); if (properties != null) { if (properties.getContentType() != null &amp;amp;amp;&amp;amp;amp; properties.getContentType().contains(&amp;#34;x-kryo&amp;#34;)) { Kryo kryo = kryoFactory.create(); content = kryo.readClassAndObject(new ByteBufferInput(message.getBody())); } else { throw new MessageConversionException(&amp;#34;Converter not applicable to this message&amp;#34;); } } return content; } private class DefaultKryoFactory implements KryoFactory { @Override public Kryo create() { Kryo kryo = new Kryo(); return kryo; } } }</description></item><item><title>Rabbitmq延迟队列实现</title><link>https://atbug.com/rabbitmq-delay-queue-implementation/</link><pubDate>Wed, 30 Mar 2016 14:27:02 +0000</pubDate><guid>https://atbug.com/rabbitmq-delay-queue-implementation/</guid><description>
在requeue=false的情况系，消息被client reject 消息过期 队列长度超过限制</description></item><item><title>关于SLF4J</title><link>https://atbug.com/about-slf4j/</link><pubDate>Sat, 18 Apr 2015 11:16:26 +0000</pubDate><guid>https://atbug.com/about-slf4j/</guid><description>
Spring的功能越来越强大，同时也越来越臃肿。比如想快速搭建一个基于Spring的项目，解决依赖问题非常耗时。Spring的项目模板的出现就解决了这个问题，通过这个描述文件，可以快速的找到你所需要的模板。 第一次认识SLF4J就是在这些项目模板里，它的全称是Simple Logging Facade for Java。从字面上可以看出它只是一个Facade，不提供具体的日志解决方案，只服务于各个日志系统。简单说有了它，我们就可以随意的更换日志系统（如java.util.logging、logback、log4j）。比如在开发的时候使用logback，部署的时候可以切换到log4j；如果关闭所有的log，切换到NOP就可以了。只</description></item></channel></rss>