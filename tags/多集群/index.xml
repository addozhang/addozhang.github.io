<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>多集群 on 乱世浮生</title><link>https://atbug.com/tags/%E5%A4%9A%E9%9B%86%E7%BE%A4/</link><description>Recent content in 多集群 on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 12 Mar 2023 23:45:17 +0800</lastBuildDate><atom:link href="https://atbug.com/tags/%E5%A4%9A%E9%9B%86%E7%BE%A4/index.xml" rel="self" type="application/rss+xml"/><item><title>Karmada：混合多云下的应用管理</title><link>https://atbug.com/deploy-application-on-multi-clusters-with-karmada/</link><pubDate>Sun, 12 Mar 2023 23:45:17 +0800</pubDate><guid>https://atbug.com/deploy-application-on-multi-clusters-with-karmada/</guid><description>背景 过去几年，公有云凭借着更高扩展性、灵活性、可靠性和安全性，吸引了大量的企业将应用程序部署到公有云上。随着业务规模的不断扩张，企业为了出于很多原因，如避免厂商锁定、追求更低的延迟、更高的可靠性等，选择将应用部署在更多的公有云上；也有些企业出于数据敏感性的考虑，会将部分应用部署有私有环境中。后者也更像是将上云的过程拉长。不管是多云还是混合云，基础设施都不可避免的存在着差异，企业不得不在适配底层设施上投入了大量的人力物力。
Kubernetes 的出现，完美地解决了这一问题。除了屏蔽基础设施层的差异解决了跨平台的问题，还提供自动化的容器编排、更高的扩展性、弹性和高可用性，其背后更是有着庞大的社区的支持。Kubernetes 的风靡，得到了大量企业的采用。随着时间的推移，企业使用多个 Kubernetes 集群管理应用的情况越来越普遍。
如何在跨越多个集群、甚至是混合多云的环境下来管理应用成了新的难题。Karmada 的出现正式为了解决这一难题。
Karmada Karmada 是 CNCF（Cloud Native Computing Foundation）下面的一个开源项目，旨在为 Kubernetes 集群提供一个平台来简化跨多个 Kubernetes 集群的应用程序部署和管理，并提高可用性和可扩展性。
借用一下官网的架构图。从图中可以看到 Karmada 提供了一个集中式控制平面，负责资源和策略的管理，以及资源的调度；数据平面则是其管理的集群，真正运行资源的集群。
控制平面的组件与 Kubernetes 的组件类似，也都是负责资源的调度。不同的是，Kubernetes 的控制平面负责将资源调度到计算节点，而 Karmada 的控制平面是将资源调度到某个集群。
拿 Deployment 的部署来说，在 Kubernetes 集群中，控制平面根据当前节点的资源情况选择某个或某些节点来运行 pod。在 Karmada 多集群下，创建了 Deployment 资源后，Karmada 控制平面根据策略将其调度到目标的集群：在目标集群中创建 Deployment 资源，所有集群中的副本数之和，就是期望的副本数。</description></item><item><title>kubectl foreach 在多个集群中执行 kubectl 命令</title><link>https://atbug.com/multi-clusters-operation-with-kubectl-foreach/</link><pubDate>Thu, 01 Dec 2022 08:04:02 +0800</pubDate><guid>https://atbug.com/multi-clusters-operation-with-kubectl-foreach/</guid><description>上周在写 K8s 多集群的流量调度 的 demo 部分时需要不停地在多个集群中安装组件、部署应用，或者执行各种命令。当时是通过 Linux shell 脚本并通过工具 kubectx 进行集群的切换，像这样：
或者这样：
操作繁琐，很是痛苦。
今天偶然间发现了一个 kubectl 插件 kubectl foreach ，可以在多个集群（contexts）上执行 kubectl 命令。比如 kubectl foreach cluster-1 cluster-2 -- get po -n kube-system 。
插件安装和使用很简单，通过 krew 进行安装：
kubectl krew install foreach 使用也很简单：
kubectl foreach -h Usage: kubectl foreach [OPTIONS] [PATTERN].</description></item><item><title>认识一下 Kubernetes 多集群服务 API</title><link>https://atbug.com/kubernetes-multi-cluster-api/</link><pubDate>Sun, 27 Nov 2022 22:37:11 +0800</pubDate><guid>https://atbug.com/kubernetes-multi-cluster-api/</guid><description>由于各种原因，采用 Kubernetes 的企业内部存在着几个、几十甚至上百个集群。比如处于研发流程上的考虑，不同环境下都存在独立的集群；监管层面的考虑，就地存储的用户数据需要搭配应用集群；单个集群的容量限制，无法满足业务体量；可用性要求的多云、多地、多中心；Kubernetes 原地升级成本大进而考虑新建集群，等等各种原因。然而，Kubernetes 设计之初并没有考虑多集群。
这些集群彼此之间看似独立，但又有着千丝万缕的关系。比如高可用性的多集群，实现了集群级的灾备，但集群中的服务如何实现跨集群的故障迁移？
我们先看下集群内的应用如何对集群外提供服务。由于 Kubernetes 网络隔离特性，存在着天然的网络边界，需要借助某些方案（如 Ingress、NodePort）来将服务暴露到集群外。虽然解决了连通性的问题，但是服务的注册和发现还无法解决。
通常我们将 Service 作为 Kubernetes 平台的服务注册和发现，今天要介绍的 Multi-Cluster Service（多集群服务 API，简称 MCS API） 则可以看成是 跨 Kubernetes 集群的服务注册发现。
MCS 介绍 MCS API 来自 Kubernetes Enhancement Proposal KEP-1645: Multi-Cluster Services API 目前还处于提案阶段。
MCS 的目标是既然多集群不可避免，那就定义一套 API 来实现服务的跨集群注册和发现，并且这套 API 足够轻量级，做到能够像访问本地服务一样访问其他集群的服务。</description></item></channel></rss>