<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kafka on 乱世浮生</title><link>https://atbug.com/tags/kafka/</link><description>Recent content in Kafka on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 30 Aug 2019 11:10:46 +0800</lastBuildDate><atom:link href="https://atbug.com/tags/kafka/index.xml" rel="self" type="application/rss+xml"/><item><title>如何选择Kafka Topic的分区数</title><link>https://atbug.com/how-to-choose-topic-partition-count-number-kafka/</link><pubDate>Fri, 30 Aug 2019 11:10:46 +0800</pubDate><guid>https://atbug.com/how-to-choose-topic-partition-count-number-kafka/</guid><description>
在kafka中, topic的分区是并行计算的单元. 在producer端和broker端, 可以同时并发的写数据到不同的分区中. 在consumer端, Kafka总是将某个分区分配个一个consumer线程. 因此同一个消费组内的并行度与分区数息息相关. Partition分区数的大小, 更多直接影响到消费端的吞吐(一个分区只能同一消费组的一个消费者消费). 分区数小, 消费端的吞吐就低. 但是太大也会有其他的影响 原则: 更多的分区可提高吞吐量 分区数越多打开的文件句柄越多 分区数越多降低可用性 更多的分区增加端到端的延迟 客户端需要更多的内存 归根结底还是得有个度. 如何找出这个度? 有个粗略的计算公式: max(t/p, t/c). t就是所预期吞吐</description></item><item><title>Kafka的消息可靠传递</title><link>https://atbug.com/kafka-reliable-data-delivery/</link><pubDate>Sat, 18 Nov 2017 14:01:46 +0000</pubDate><guid>https://atbug.com/kafka-reliable-data-delivery/</guid><description>
Kafka提供的基础保障可以用来构建可靠的系统, 却无法保证完全可靠. 需要在可靠性和吞吐之间做取舍. Kafka在分区上提供了消息的顺序保证. 生产的消息在写入到所有的同步分区上后被认为是已提交 (不需要刷到硬盘). 生产者可以选择在消息提交完成后接收broker的确认, 是写入leader之后, 或者所有的副本 只要有一个副本存在, 提交的消息就不会丢失 消费者只能读取到已提交的消息 复制 Kafka的复制机制保证每个分区有多个副本, 每个副本可以作为leader或者follower的角色存在. 为了保证副本的同步, 需要做到: 保持到zk的连接会话: 每隔6s向zk发送心跳, 时间可配置 每隔10s向leader拉取消息, 时间</description></item><item><title>Kafka发送不同确认方式的性能差异</title><link>https://atbug.com/kafka-producer-acknowledge-benchmark/</link><pubDate>Tue, 10 Oct 2017 11:49:58 +0000</pubDate><guid>https://atbug.com/kafka-producer-acknowledge-benchmark/</guid><description>
背景 Kafka的性能众所周知，Producer支持acknowledge模式。即Kafka会想Producer返回消息发送的结果。但是在Java Client中，acknowledge的确认有两种：同步和异步。 同步是通过调用future.get()实现的；异步则是通过提供callback方法来实现。写了个简单的程序测试一下单线程中吞吐差异能有多大。注意这里只考虑横向对比。 发送端单线程 Kafka为单集群节点 topic的分区数为1 key长度1 payload长度100 测试工具 JMeter Kafka Meter future.get() + batch size =1 Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: http://7xvxng.com1.z0.glb.clouddn.com/15076056852541.jpg 链接到文件: /static/http://7xvxng.com1.z0.glb.clouddn.com/15076056852541.jpg 使用 Page Bundles: false future.get() + batch size = 16K Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important;</description></item><item><title>Kafka消息消费一致性</title><link>https://atbug.com/kafka-consumer-consistency/</link><pubDate>Tue, 26 Sep 2017 19:13:48 +0000</pubDate><guid>https://atbug.com/kafka-consumer-consistency/</guid><description>
Kafka消费端的offset主要由consumer来控制, Kafka降每个consumer所监听的tocpic的partition的offset保存在__consumer_offsets主题中. consumer需要将处理完成的消息的offset提交到服务端, 主要有ConsumerCoordinator完成的. 每次从kafka拉取数据之前, 假如是异步提交offset, 会先调用已经完成的offset commit的callBack, 然后检查ConsumerCoordinator的连接状态. 如果设置了自动提交offset, 会继续上次从服务端获取的数据的offset异步提交到服务端. 这里需要注意的是会</description></item><item><title>Kafka 恰好一次发送和事务消费示例</title><link>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging-example/</link><pubDate>Fri, 22 Sep 2017 18:03:43 +0000</pubDate><guid>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging-example/</guid><description>
核心思想 生产端一致性: 开启幂等和事务, 包含重试, 发送确认, 同一个连接的最大未确认请求数. 消费端一致性: 通过设置读已提交的数据和同时处理完成每一条消息之后手动提交offset. 生产端 public class ProducerTest { public static void main(String[] args) throws InterruptedException, ExecutionException { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &amp;#34;my-transactional-id&amp;#34;); props.put(ProducerConfig.ACKS_CONFIG, &amp;#34;all&amp;#34;); props.put(ProducerConfig.RETRIES_CONFIG, &amp;#34;3&amp;#34;); props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, &amp;#34;1&amp;#34;); Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props, new StringSerializer(), new StringSerializer()); producer.initTransactions(); try { producer.beginTransaction(); for (int i = 0; i &amp;lt; 5; i++) { Future&amp;lt;RecordMetadata&amp;gt; send = producer .send(new ProducerRecord&amp;lt;&amp;gt;(&amp;#34;my-topic&amp;#34;, Integer.toString(i), Integer.toString(i))); System.out.println(send.get().offset()); TimeUnit.MILLISECONDS.sleep(1000L); } producer.commitTransaction(); } catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) { // We can&amp;#39;t recover from these exceptions, so our only option is to close the producer and exit. producer.close(); } catch (KafkaException e) { // For all other exceptions, just abort the transaction and try again. producer.abortTransaction(); } producer.close(); } } 消费端 public class ConsumerTest { public static void main(String[] args) throws InterruptedException { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ConsumerConfig.GROUP_ID_CONFIG, &amp;#34;test&amp;#34;); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, OffsetResetStrategy.NONE.toString().toLowerCase(Locale.ROOT)); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &amp;#34;false&amp;#34;); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, &amp;#34;org.apache.kafka.common.serialization.StringDeserializer&amp;#34;); props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase(Locale.ROOT)); KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props); consumer.subscribe(Arrays.asList(&amp;#34;my-topic&amp;#34;)); while (true) { ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100); if (!records.isEmpty()) { for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records) { System.out.printf(&amp;#34;offset = %d, key = %s, value = %s%n&amp;#34;, record.offset(), record.key(), record.value()); //Manually commit each record consumer.commitSync(Collections.singletonMap(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1))); } } } } }</description></item><item><title>恰好一次发送和事务消息(译)</title><link>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging/</link><pubDate>Tue, 19 Sep 2017 19:13:26 +0000</pubDate><guid>https://atbug.com/kafka-exactly-once-delivery-and-transactional-messaging/</guid><description>
Kafka提供“至少一次”交付语义, 这意味着发送的消息可以传送一次或多次. 人们真正想要的是“一次”语义,因为重复的消息没有被传递。 普遍地发声重复消息的情况有两种: 如果客户端尝试向集群发送消息并获取网络错误, 则重试可能会导致重复. 如果在发送消息之前发生网络错误, 则不会发生重复. 但是, 如果在将消息附加到日志之后发生网络错误, 但在将响应发送给发件人之前, 发件人将不知道发生了什么. 唯一的选择是重试和冒险重复或放弃并声明消息丢失。 如果客户端尝试向集群发送消息并获取网络错误, 则重试可能会导致重复. 如果在发送消息之前发生网络错误, 则不会发生重复. 但是, 如果在将消息附加到日志之后发生网络错误, 但在将响应发送给</description></item><item><title>Kafka Producer配置解读</title><link>https://atbug.com/kafka-producer-config/</link><pubDate>Tue, 19 Sep 2017 15:38:03 +0000</pubDate><guid>https://atbug.com/kafka-producer-config/</guid><description>
按照重要性分类, 基于版本0.11.0.0 高 bootstrap.servers 一组host和port用于初始化连接. 不管这里配置了多少台server, 都只是用作发现整个集群全部server信息. 这个配置不需要包含集群所有的机器信息. 但是最好多于一个, 以防服务器挂掉. key.serializer 用来序列化key的Serializer接口的实现类. value.serializer 用来序列化value的Serializer接口的实现类 acks producer希望leader返回的用于确认请求完成的确认数量. 可选值 all, -1, 0 1. 默认值为1 acks=0 不需要等待服务器的确认. 这是retries设置无效. 响应里来自服务端的offset总是-1. producer只管发不管发送成功与否。延迟低，容易丢失数据。 acks=1 表示le</description></item><item><title>消费时offset被重置导致重复消费</title><link>https://atbug.com/offset-be-reset-when-consuming/</link><pubDate>Mon, 20 Feb 2017 13:23:49 +0000</pubDate><guid>https://atbug.com/offset-be-reset-when-consuming/</guid><description>
这是实际使用时遇到的问题：kafka api的版本是0.10，发现有重复消费问题；检查log后发现在commit offset的时候发生超时。 Auto offset commit failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records. 15:12:12.364 [main] WARN o.a.k.c.c.i.ConsumerCoordinator - Auto offset commit failed for group test: Commit offsets failed with retriable exception. You should retry committing offsets. 看了Kafka的API文档，发现0.10中提供了新的配置max.poll.records： The maximum number of records returned in a single call to poll(). type: int default: 2147483647 如果生产端写入很快，消费端处理耗时。一个batch的处理时间大于session.timeout.ms，会导致session time out，引起of</description></item><item><title>Kafka Java生产者模型</title><link>https://atbug.com/kafka-java-producer-model/</link><pubDate>Wed, 04 Jan 2017 16:33:02 +0000</pubDate><guid>https://atbug.com/kafka-java-producer-model/</guid><description>
Image not found a.warning-link { color: inherit !important; font-weight: inherit !important; text-decoration: underline !important; border-bottom: none !important; } 网站链接: https://atbug.com/media/14835174309242.jpg 链接到文件: /static//media/14835174309242.jpg 使用 Page Bundles: false Producer初始化 初始化KafkaProducer实例，同时通过Config数据初始化MetaData、NetWorkClient、Accumulator和Sender线程。启动Sender线程。 MetaData信息 记录Cluster的相关信息，第一次链接使用Config设置，之后会从远端poll信息回来，比如host.name等信息。 Accumulator实例 Accumulator持有一个Map实例，key为TopicPartition（封装了topic和partition信息）对象，Value为RecordBatc</description></item></channel></rss>