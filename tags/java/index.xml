<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java on 乱世浮生</title><link>https://atbug.com/tags/java/</link><description>Recent content in Java on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 27 Jan 2022 11:07:34 +0800</lastBuildDate><atom:link href="https://atbug.com/tags/java/index.xml" rel="self" type="application/rss+xml"/><item><title>使用 sdkman 在 M1 Mac 上 安装 graalvm jdk</title><link>https://atbug.com/articles/install-graalvm-on-m1-mac-with-sdkman/</link><pubDate>Thu, 27 Jan 2022 11:07:34 +0800</pubDate><guid>https://atbug.com/articles/install-graalvm-on-m1-mac-with-sdkman/</guid><description>&lt;p>SDKMAN 是一款管理多版本 SDK 的工具，可以实现在多个版本间的快速切换。安装和使用非常简单：&lt;/p></description></item><item><title>使用 Flomesh 进行 Dubbo 服务治理</title><link>https://atbug.com/articles/enhance-dubbo-service-governance-with-flomesh/</link><pubDate>Wed, 18 Aug 2021 09:50:28 +0800</pubDate><guid>https://atbug.com/articles/enhance-dubbo-service-governance-with-flomesh/</guid><description>写在最前 和上一篇《使用 Flomesh 强化 Spring Cloud 服务治理》一样，这次同样是在无代码侵入的情况下对 Dubbo 服务治理的提升。
更多治理场景陆续添加中，有兴趣的可关注 https://github.com/flomesh-io/service-mesh-dubbo-demo。
开源的 Pipy 作为 Flomesh 的核心，得益于其轻量及灵活性可以通过编程的方式轻松快速的支持多中平台的服务发现机制，比如 Eureka、Consul、Nacos 等。
概览 细节 环境搭建 搭建 Kubernetes 环境，可以选择 kubeadm 进行集群搭建。也可以选择 minikube、k3s、Kind 等，本文使用 k3s。
使用 k3d 安装 k3s。k3d 将在 Docker 容器中运行 k3s，因此需要保证已经安装了 Docker。
$ k3d cluster create dubbo-demo -p &amp;#34;80:80@loadbalancer&amp;#34; --k3s-server-arg &amp;#39;--no-deploy=traefik&amp;#39; 安装 Flomesh 从仓库 https://github.</description></item><item><title>使用 Flomesh 强化 Spring Cloud 服务治理</title><link>https://atbug.com/articles/enhance-springcloud-service-governance-with-flomesh/</link><pubDate>Tue, 17 Aug 2021 18:47:33 +0800</pubDate><guid>https://atbug.com/articles/enhance-springcloud-service-governance-with-flomesh/</guid><description>写在最前 这篇是关于如何使用 Flomesh 服务网格来强化 Spring Cloud 的服务治理能力，降低 Spring Cloud 微服务架构落地服务网格的门槛，实现“自主可控”。
文档在 github 上持续更新，欢迎大家一起讨论：https://github.com/flomesh-io/flomesh-bookinfo-demo。
架构 环境搭建 搭建 Kubernetes 环境，可以选择 kubeadm 进行集群搭建。也可以选择 minikube、k3s、Kind 等，本文使用 k3s。
使用 k3d 安装 k3s。k3d 将在 Docker 容器中运行 k3s，因此需要保证已经安装了 Docker。
$ k3d cluster create spring-demo -p &amp;#34;81:80@loadbalancer&amp;#34; --k3s-server-arg &amp;#39;--no-deploy=traefik&amp;#39; 安装 Flomesh 从仓库 https://github.</description></item><item><title>使用 Quarkus 和 MicroProfile 实现微服务特性</title><link>https://atbug.com/articles/microservicilities-quarkus/</link><pubDate>Wed, 26 May 2021 07:37:04 +0800</pubDate><guid>https://atbug.com/articles/microservicilities-quarkus/</guid><description>Quarkus 的文章之前写过三篇了，讲过了 Quarkus 的小而快。
Hello, Quarkus 应&amp;quot;云&amp;quot;而生的 Java 框架 Quarkus：构建本机可执行文件 谁说 Java 不能用来跑 Serverless？ 一直在酝酿写一篇 Quarkus 生态相关的，因为最近一直在忙 Meetup 的事情而搁浅。正好看到了这篇文章，就拿来翻译一下，补全云原生中的“微服务”这一块。
本文译自《Implementing Microservicilities with Quarkus and MicroProfile》 。
为什么要使用微服务特性？ 在微服务架构中，一个应用程序是由几个相互连接的服务组成的，这些服务一起工作来实现所需的业务功能。
因此，典型的企业微服务架构如下所示：
刚开始，使用微服务架构实现应用程序看起来很容易。
但是，因为有了单体架构没有一些新的挑战，因此做起来并不容器
举几个例子，比如容错、服务发现、扩展性、日志记录和跟踪。
为了解决这些挑战，每个微服务都应实现我们在 Red Hat 所说的“微服务特性”。
该术语是指除业务逻辑以外，服务还必须实现来解决的跨领域关注点清单，如下图所示： 可以用任何语言（Java、Go、JavaScript）或任何框架（Spring Boot、Quarkus）实现业务逻辑，但是围绕业务逻辑，应实现以下关注点：</description></item><item><title>Quarkus：谁说 Java 不能用来跑 Serverless？</title><link>https://atbug.com/articles/quarkus-enable-java-running-in-serverless/</link><pubDate>Sat, 24 Apr 2021 09:16:05 +0800</pubDate><guid>https://atbug.com/articles/quarkus-enable-java-running-in-serverless/</guid><description>想到这个标题的时候，我第一时间想到的就是星爷的《唐伯虎点秋香》的这一幕。
当讨论起世界上最好的开发语言是什么的时候，Java 的粉丝们总会遇到这种场景：
吹：“Java 语法简单，容易上手！” 黑：“Java 启动慢，性能差，耗资源！” 吹：“Java 有世界上最多的程序员！” 黑：“Java 启动慢，性能差，耗资源！” 吹：“Java 生态好！” 黑：“Java 启动慢，性能差，耗资源！” 吹：“滚！”
今天我们继续说说 Quarkus，应“云”而生的 Java 框架。今天算是第三篇了，没看过的同学可以回顾一下：
Hello, Quarkus 应&amp;quot;云&amp;quot;而生的 Java 框架 Quarkus：构建本机可执行文件 上一篇的结尾预告：试试 Quarkus 在 ArgoCD 中的应用，看下 Serverless 上的使用体验。不过不想用 ArgoCD 了，因为这 workflow 这种场景实在体现不出 Quarkus 到底有多快。但又想做 Serverless，那就想到了 Knative Serving 了。</description></item><item><title>应“云”而生的 Java 框架：构建本机可执行文件</title><link>https://atbug.com/articles/quarkus-build-native-executable-file/</link><pubDate>Sat, 17 Apr 2021 09:08:40 +0800</pubDate><guid>https://atbug.com/articles/quarkus-build-native-executable-file/</guid><description>电影《功夫》中，火云邪神有句话：“天下武功无坚不摧，唯快不破。”
在 上一篇文章 中，我们写了第一个 Quarkus 应用，并尝试着构建了 legacy-jar 和 fast-jar。
今天来看一下 Quarkus 构建出来的本机可执行文件到底比 Spring 应用能快多少，生态的成熟度不在这里讨论。
TLDR 先上结论， 与只有一个 Controller 的Spring Web 应用做下对比。
应用启动时间：0.012s vs 2.294s 镜像大小：49MB vs 237 MB Spring 应用镜像使用 openjdk:11.0-jre-slim 作为 base 镜像，大小为 220MB。
docker images REPOSITORY TAG IMAGE ID CREATED SIZE spring/spring-getting-started latest 5f47030c5c3f 6 minutes ago 237MB quarkus/quarkus-getting-started distroless2 fe973c5ac172 24 minutes ago 49MB quarkus/quarkus-getting-started distroless 6fe27dd44e86 31 minutes ago 51MB quarkus/quarkus-getting-started ubi 8f86f5915715 58 minutes ago 132MB Java 应用容器化的困境 云原生世界中，应用容器化是个显著的特点。Java 应用容器化时面临了如下问题：</description></item><item><title>应“云”而生的 Java 框架：Hello, Quarkus</title><link>https://atbug.com/articles/hello-quarkus/</link><pubDate>Mon, 05 Apr 2021 21:08:40 +0800</pubDate><guid>https://atbug.com/articles/hello-quarkus/</guid><description>Wikipedia上有关 Quarkus 的信息还很少，只有一句简单的介绍：
Quarkus 是专为 OpenJDK HotSpot 和 GraalVM 定制的全栈 Kubernetes 原生 Java 应用程序框架。与如 Spring 之类的其他框架相比，它提供了较小的内存占用并缩短了启动时间。它允许结合命令式和非阻塞响应式编程。
从 Quarkus 的官网，可以看到其有几个特性：
容器优先 统一了命令式和响应式编程 开发者友好 最佳品种的库及标准 更多 Quarkus 可以参考官网的介绍及文档。今天主要就是跑一下 Quarkus 的 Hello world。
放一张官网的图：
环境准备 基于 Java 11 的 GraalVM Maven 3.</description></item><item><title>带你了解 Ribbon 负载均衡器的实现</title><link>https://atbug.com/articles/how-loadbalancer-works-in-ribbon/</link><pubDate>Tue, 09 Jun 2020 19:35:53 +0800</pubDate><guid>https://atbug.com/articles/how-loadbalancer-works-in-ribbon/</guid><description>Spring Cloud 中 Ribbon有在 Zuul 和 Feign 中使用，当然也可以通过在RestTemplate的 bean 定义上添加@LoadBalanced注解方式获得一个带有负载均衡更能的RestTemplate。
不过实现的方法都大同小异：对HttpClient进行封装，加上实例的”选择“（这个选择的逻辑就是我们所说的负载均衡）。
要学习某个框架的时候，最简单的方案就是：Running+Debugging。
跑就是了。
debug 不一定是为了 bug
debug 出真知
Debugging = Learning
选用 Ali Spittel 的一条推文：
以 Zuul 路由的线程栈为例 调整下顺序：
RetryableRibbonLoadBalancingHttpClient#execute(RibbonApacheHttpRequest, IClientConfig) RetryableRibbonLoadBalancingHttpClient#executeWithRetry(...) RetryTemplate#execute(RetryCallback&amp;lt;T, E&amp;gt;, RecoveryCallback&amp;lt;T&amp;gt;) RetryTemplate#doExecute(RetryCallback&amp;lt;T, E&amp;gt;, RecoveryCallback&amp;lt;T&amp;gt;, RetryState) RetryTemplate#canRetry(RetryPolicy, RetryContext) InterceptorRetryPolicy#canRetry(RetryContext) AbstractLoadBalancingClient#choose(String serviceId) ZoneAwareLoadBalancer#chooseServer(Object key) //key as serviceId BaseLoadBalancer#chooseServer(Object key) PredicateBasedRule#choose(Object key) AbstractServerPredicate#chooseRoundRobinAfterFiltering(List&amp;lt;Server&amp;gt; servers, Object loadBalancerKey) AbstractServerPredicate#apply(Predicate) 分析 Zuul 收到请求经过一系列 Filter 的处理，来到 RibbonRoutingFilter；将请求封装成 RibbonCommandContext，然后使用 context 构建 RibbonCommand。最终调用RibbonCommand#execute()方法，将请求路由到下游。</description></item><item><title>Java 中的 Mysql 时区问题</title><link>https://atbug.com/articles/mysql-timezone-in-java/</link><pubDate>Thu, 14 May 2020 11:34:24 +0800</pubDate><guid>https://atbug.com/articles/mysql-timezone-in-java/</guid><description>(Photo by Andrea Piacquadio from Pexels)
话说工作十多年，mysql 还真没用几年。起初是外企银行，无法直接接触到 DB；后来一直从事架构方面，也多是解决问题为主。
这次搭建海外机房，围绕时区大家做了一番讨论。不说最终的结果是什么，期间有同事认为 DB 返回的是 UTC 时间。
这里简单做个验证，顺便看下时区的问题到底是如何处理。
环境 openjdk version &amp;ldquo;1.8.0_242&amp;rdquo; mysql-connector-java &amp;ldquo;8.0.20&amp;rdquo; mysql &amp;ldquo;5.7&amp;rdquo; 时区 TZ=Europe/London 本地时区 GMT+8
创建个简单的库test及表user， 表结构如下：
CREATE TABLE `user` ( `name` varchar(50) NOT NULL, `birth_date` timestamp NULL DEFAULT CURRENT_TIMESTAMP ) ENGINE=InnoDB DEFAULT CHARSET=latin1 插入一条测试数据：</description></item><item><title>加速云原生的 Java 开发</title><link>https://atbug.com/articles/speed-up-java-development-on-kubernetes/</link><pubDate>Sat, 21 Dec 2019 20:45:22 +0800</pubDate><guid>https://atbug.com/articles/speed-up-java-development-on-kubernetes/</guid><description>今天来说说日常在Kubernetes开发Java项目遇到的问题.
当我们新建一个项目的时候, 总是面临需要新建manifest, 平时都是copy+paste+modify. 能否以变成的方式来生成?
开发时的步骤也比较繁琐: docker build, docker push, kubectl apple, kubectl delete pod. 对于一个Java应用来说还多了一步编译. 操作一次还ok, 但是一天十几次总会有想吐的感觉. 这些步骤能否简化成一个命令, 甚至修改了代码自动就完成上面一系列的操作?
实现这些我们需要几个工具: dekorate, Jib, Skaffold. 其中Jib也在上一篇文章使用Jib为Java应用构建镜像中介绍过.
dekorate Dekorate is a collection of Java compile-time generators and decorators for Kubernetes/OpenShift manifests. Dekorate是Java编译时生成和装饰Kubernetes/OpenShift的manifests的工具</description></item><item><title>Spring Boot 2.2.0 发布</title><link>https://atbug.com/articles/spring-boot-2-2-0-release/</link><pubDate>Tue, 22 Oct 2019 09:27:03 +0800</pubDate><guid>https://atbug.com/articles/spring-boot-2-2-0-release/</guid><description>译自: https://spring.io/blog/2019/10/16/spring-boot-2-2-0
组件升级 Spring AMQP 2.2 Spring Batch 4.2 Spring Data Moore Spring Framework 5.2 Spring HATEOAS 1.0 Spring Integration 5.2 Spring Kafka 2.3 Spring Security 5.2 Spring Session Corn 第三方库升级 Elasticsearch 6.7 Flyway 6.0 Jackson 2.10 JUnit 5.</description></item><item><title>如何选择Kafka Topic的分区数</title><link>https://atbug.com/articles/how-to-choose-topic-partition-count-number-kafka/</link><pubDate>Fri, 30 Aug 2019 11:10:46 +0800</pubDate><guid>https://atbug.com/articles/how-to-choose-topic-partition-count-number-kafka/</guid><description>在kafka中, topic的分区是并行计算的单元. 在producer端和broker端, 可以同时并发的写数据到不同的分区中. 在consumer端, Kafka总是将某个分区分配个一个consumer线程. 因此同一个消费组内的并行度与分区数息息相关.
Partition分区数的大小, 更多直接影响到消费端的吞吐(一个分区只能同一消费组的一个消费者消费). 分区数小, 消费端的吞吐就低. 但是太大也会有其他的影响
原则:
更多的分区可提高吞吐量 分区数越多打开的文件句柄越多 分区数越多降低可用性 更多的分区增加端到端的延迟 客户端需要更多的内存 归根结底还是得有个度. 如何找出这个度?
有个粗略的计算公式: max(t/p, t/c). t就是所预期吞吐量, p是当前生产端单个分区的吞吐, 那c就是消费端单个分区的吞吐.
比如单个partition的生产端吞吐是200, 消费端是100. 预期的吞吐是500, 那么partition的数量就是5.
单个分区的吞吐通常通过修改配置来提升, 比如生产端的批处理大小, 压缩算法, acknowledgement类型, 副本数等. 而在消费端则更依赖于消息的处理速度.
参考 Confluent博客 Linkedin的benchmark</description></item><item><title>Spring Boot源码分析 - Configuration注解</title><link>https://atbug.com/articles/spring-boot-configuration-annotation/</link><pubDate>Mon, 10 Dec 2018 16:24:33 +0000</pubDate><guid>https://atbug.com/articles/spring-boot-configuration-annotation/</guid><description>@Configuration注解 @Configuration注解指示一个类声明一个或多个@Bean方法, 并且可以由Spring容器处理, 以在运行时为这些bean生成bean定义和服务请求.
使用ConfigurationClassParser来对@Configuration标注的类进行解析, 封装成ConfigurationClass实例. 具体的实现通过ConfigurationClassPostProcessor来实现的.
ConfigurationClassPostProcessor 实现了BeanDefinitionRegistryPostProcessor接口, 间接实现了BeanFactorPostProcessor接口.
#postProcessBeanDefinitionRegistry(): 注册所有ConfigurationClass中的BeanDefinition, 包括@Bean注解的方法, @ImporResource引入的资源中定义的bean, 和@Import注解引入的ImportBeanDefinitionRegistrar中注册的BeanDefinition #postProcessBeanFactory(): 在运行时以通过cglig增强的类来替换ConfigurationClass, 为服务bean请求做准备. 增强的实现是通过ConfigurationClassEnhancer完成的. 插入一点, ConfigurationClassEnhancer实现了直接使用bean注册方法来获取bean的操作, 提供了一个BeanMethodInterceptor的内部类来实行.
@Configuration public class Config { @Bean public A a() { ... return a; } @Bean public B b() { b.</description></item><item><title>Zuul网关Ribbon重试</title><link>https://atbug.com/articles/ribbon-retry-in-zuul/</link><pubDate>Thu, 02 Aug 2018 08:55:43 +0000</pubDate><guid>https://atbug.com/articles/ribbon-retry-in-zuul/</guid><description>相关配置 #如果路由转发请求发生超时(连接超时或处理超时), 只要超时时间的设置小于Hystrix的命令超时时间,那么它就会自动发起重试. 默认为false. 或者对指定响应状态码进行重试 zuul.retryable = true zuul.routes.&amp;lt;route&amp;gt;.retryable = false #同一实例上的最大重试次数, 默认值为0. 不包括首次调用 ribbon.MaxAutoRetries=0 #重试其他实例的最大重试次数, 不包括第一次选的实例. 默认为1 ribbon.MaxAutoRetriesNextServer=1 #是否所有操作执行重试, 默认值为false, 只重试`GET`请求 ribbon.OkToRetryOnAllOperations=false #连接超时, 默认2000 ribbon.ConnectTimeout=15000 #响应超时, 默认5000 ribbon.ReadTimeout=15000 #每个host的最大连接数 ribbon.MaxHttpConnectionsPerHost=50 #最大连接数 ribbon.MaxTotalHttpConnections=200 #何种响应状态码才进行重试 ribbon.retryableStatusCodes=404,502 实现 SimpleRouteLocator#getRoute返回的route对象中会带上retryable的设置. PreDecorationFilter在对RequestContext进行装饰的时候会将retryable的设置通过keyFilterConstants.RETRYABLE_KEY注入RequestContext中. RibbonRoutingFilter#buildCommandContext会使用RequestContext的retryable设置构造RibbonCommandContext对象. RibbonCommandFactory使用RibbonCommandContext构建出RibbonCommand对象.</description></item><item><title>Hystrix工作原理三</title><link>https://atbug.com/articles/hystrix-exception-handling/</link><pubDate>Sun, 24 Jun 2018 16:20:16 +0000</pubDate><guid>https://atbug.com/articles/hystrix-exception-handling/</guid><description>异常处理 Hystrix异常类型 HystrixRuntimeException HystrixBadRequestException HystrixTimeoutException RejectedExecutionException HystrixRuntimeException HystrixCommand失败时抛出, 不会触发fallback.
HystrixBadRequestException 用提供的参数或状态表示错误的异常, 而不是执行失败. 与其他HystrixCommand抛出的异常不同, 这个异常不会触发fallback, 也不会记录进failure的指标, 因而也不会触发断路器,
应该在用户输入引起的错误是抛出, 否则会它与容错和后退行为的目的相悖.
不会触发fallback, 也不会记录到错误的指标中, 也不会触发断路器.
RejectedExecutionException 线程池发生reject时抛出
HystrixTimeoutException 在HystrixCommand.run()或者HystrixObservableCommand.construct()时抛出, 会记录timeout的次数. 如果希望某些类型的失败被记录为timeout, 应该将这些类型的失败包装为HystrixTimeoutException
异常处理 ignoreExceptions
final Func1&amp;lt;Throwable, Observable&amp;lt;R&amp;gt;&amp;gt; handleFallback = new Func1&amp;lt;Throwable, Observable&amp;lt;R&amp;gt;&amp;gt;() { @Override public Observable&amp;lt;R&amp;gt; call(Throwable t) { circuitBreaker.</description></item><item><title>Hystrix工作原理二</title><link>https://atbug.com/articles/hystrix-isolation/</link><pubDate>Sun, 24 Jun 2018 16:18:52 +0000</pubDate><guid>https://atbug.com/articles/hystrix-isolation/</guid><description>隔离策略 线程和线程池 客户端(库, 网络调用等)在各自的线程上运行. 这种做法将他们与调用线程隔开, 因此调用者可以从一个耗时的依赖调用&amp;quot;离开(walk away)&amp;quot;
Hystrix使用单独的, 每个依赖的线程池作为约束任何给定依赖的一种方式, 因此潜在执行的延迟将仅在该池中使可用线程饱和.
如果不试用线程池可以保护你免受故障的影响, 但是这需要客户端可信任地快速失败(网络连接/读取超时, 重试的配置)并始终表现良好.
在Hystrix的设计中, Netflix选择试用线程和线程池来达到隔离的目的, 原因有:
很多应用程序调用了由很多不同的团队开发的许多(有时超过1000)不同的后端服务 每个服务都各自提供了其客户端库 客户端库不断地在更新 客户端库可能被添加使用新的网络调用 客户端库的逻辑中可能包含重试, 数据解析, 缓存(内存或者跨网络)和其他类似的行为 客户端库更类似于一个黑盒, 其实现细节, 网络访问模式, 默认配置等是对使用者不透明的 在实际的生产问题中, 根源经常是 &amp;ldquo;有些东西改变了, 配置应该被修改&amp;rdquo; 或者 &amp;ldquo;客户端库修改了逻辑&amp;rdquo; 即使客户端没有改变, 服务端自身发生了变会员. 这种变化会是客户端设置无效而影响性能特性 传递依赖会引入其他客户端, 这些客户端不是可预期的, 也可能没有被正确地配置 大多数网络访问是同步的 失败和延迟也可能发生在客户端, 不只是网络调用 线程池的优势 该应用程序完全免受失控客户端库的保护.</description></item><item><title>Hystrix工作原理一</title><link>https://atbug.com/articles/how-hystrix-works/</link><pubDate>Mon, 04 Jun 2018 08:47:40 +0000</pubDate><guid>https://atbug.com/articles/how-hystrix-works/</guid><description>运行时的流程图 构建HystrixCommand或者HystrixObservableCommand对象
第一步是构建一个HystrixCommand或HystrixObservableCommand对象来代表对依赖服务所做的请求。 将在请求发生时将需要的任何参数传递给构造函数。
如果依赖的服务预期会返回单一的响应, 构造一个HystrixCommand对象, 例如:
HystrixCommand command = new HystrixCommand(arg1, arg2); 如果依赖的服务预期会返回一个发出响应的Observable对象, 则构造一个HystrixObservableCommand对象, 例如:
HystrixObservableCommand command = new HystrixObservableCommand(arg1, arg2); 执行Command
响应是否被缓存?
如果Command的缓存请求被开启, 同时请求的响应在缓存中可用, 缓存的响应被立即以一个Observable的方式返回.
断路器是否开启?
执行Command时, Hystrix会检查断路器(circuti-breaker)是否开始回路(circuit).
如果回路开启, Hystrix将不会执行Command, 而直接去到流程8: Get the Fallback 如果关闭, 则执行流程5检查是否有足够的容量来运行该命令</description></item><item><title>初识 Netflix Zuul</title><link>https://atbug.com/articles/learn-netflix-zuul/</link><pubDate>Sun, 11 Feb 2018 10:07:18 +0000</pubDate><guid>https://atbug.com/articles/learn-netflix-zuul/</guid><description>&lt;p>嵌入式的zuul代理&lt;/p>
&lt;p>使用了Netfilx OSS的其他组件:&lt;/p>
&lt;ul>
&lt;li>Hystrix 熔断&lt;/li>
&lt;li>Ribbon 负责发送外出请求的客户端, 提供软件负载均衡功能&lt;/li>
&lt;li>Trubine 实时地聚合细粒度的metrics数据&lt;/li>
&lt;li>Archaius 动态配置&lt;/li>
&lt;/ul>
&lt;h2 id="介绍">介绍&lt;/h2>
&lt;p>由于2.0停止开发且会有bug, 故下面的分析基于1.x版本.&lt;/p>
&lt;h3 id="特性">特性&lt;/h3>
&lt;ul>
&lt;li>Authentication 认证&lt;/li>
&lt;li>Insights 洞察&lt;/li>
&lt;li>Stress Testing 压力测试&lt;/li>
&lt;li>Canary Testing 金丝雀测试&lt;/li>
&lt;li>Dynamic Routing 动态路由&lt;/li>
&lt;li>Multi-Region Resiliency 多区域弹性&lt;/li>
&lt;li>Load Shedding 负载脱落&lt;/li>
&lt;li>Security 安全&lt;/li>
&lt;li>Static Response handling 静态响应处理&lt;/li>
&lt;li>Multi-Region Resiliency 主动/主动流量管理&lt;/li>
&lt;/ul></description></item><item><title>ConfigurationProperties到底需不需要getter</title><link>https://atbug.com/articles/configurationproperties-requires-getter-or-not/</link><pubDate>Wed, 07 Feb 2018 15:53:21 +0000</pubDate><guid>https://atbug.com/articles/configurationproperties-requires-getter-or-not/</guid><description>为什么要讨论这个问题, 工作中一个同事写的类使用了ConfigurationProperties, 只提供了标准的setter方法. 属性的访问, 提供了定制的方法. 可以参考EurekaClientConfigBean.
他使用的是spring boot 2.0.0.M5版本, 可以正常获取配置文件中的属性值, 但是在1.5.8.RELEASE获取不到.
看下文档和源码:
Annotation for externalized configuration. Add this to a class definition or a @Bean method in a @Configuration class if you want to bind and validate some external Properties (e.</description></item><item><title>SpringBoot源码 - 启动</title><link>https://atbug.com/articles/glance-over-spring-boot-source/</link><pubDate>Fri, 08 Dec 2017 17:48:43 +0000</pubDate><guid>https://atbug.com/articles/glance-over-spring-boot-source/</guid><description>SpringBoot Application启动部分的源码阅读.
SpringApplication 常用的SpringApplication.run(Class, Args)启动Spring应用, 创建或者更新ApplicationContext
静态方法run 使用source类实例化一个SpringApplication实例, 并调用实例方法run.
public static ConfigurableApplicationContext run(Object[] sources, String[] args) { return new SpringApplication(sources).run(args); } 初始化initialize 实例化的时候首先通过尝试加载javax.servlet.Servlet和org.springframework.web.context.ConfigurableWebApplicationContext推断当前是否是web环境.
然后从spring.factories获取ApplicationContextInitializer的实现类.
从spring.factories获取ApplicationListener的实现类
推断出应用的启动类(包含main方法的类): 检查线程栈中元素的方法名是否是main
private Class&amp;lt;?&amp;gt; deduceMainApplicationClass() { try { //获取线程栈数据 StackTraceElement[] stackTrace = new RuntimeException().</description></item><item><title>Java序列化工具性能对比</title><link>https://atbug.com/articles/java-serval-serializer-benchmark/</link><pubDate>Sat, 02 Dec 2017 07:35:43 +0000</pubDate><guid>https://atbug.com/articles/java-serval-serializer-benchmark/</guid><description>最近在调整系统的性能, 系统中正使用Jackson作为序列化工具. 做了下与fastJson, Avro, ProtoStuff的序列化吞吐对比.
由于只是做横向对比, 没有优化系统或者JVM任何参数. 服务器一般都用Linux, 在Docker里做了Linux系统的测试.
Mac:
Benchmark Mode Cnt Score Error Units JMHTest.avroSerializer thrpt 2 3124799.325 ops/s JMHTest.fastJsonSerializer thrpt 2 3122720.917 ops/s JMHTest.jacksonSerializer thrpt 2 2373347.208 ops/s JMHTest.protostuffSerializer thrpt 2 4196009.673 ops/s Docker:
Benchmark Mode Cnt Score Error Units JMHTest.</description></item><item><title>Spring Cloud - Eureka Client源码分析</title><link>https://atbug.com/articles/spring-cloud-eureka-client-source-code-analysis/</link><pubDate>Sat, 14 Oct 2017 22:04:59 +0000</pubDate><guid>https://atbug.com/articles/spring-cloud-eureka-client-source-code-analysis/</guid><description>准备做个Spring Cloud源码分析系列, 作为Spring Cloud的源码分析笔记.
这一篇是Eureka的客户端.
客户端 两种方式, 最终的实现基本一样.
显示指定服务发现的实现类型 使用@EnableEurekaClient注解显示的指定使用Eureka作为服务发现的实现, 并实例化EurekaClient实例. 实际上使用的是@EnableDiscoveryClient注解.
@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @EnableDiscoveryClient public @interface EnableEurekaClient { } 动态配置实现 使用@EnableDiscoveryClient注解来配置服务发现的实现.
源码分析 EnableDiscoveryClient
@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @Import(EnableDiscoveryClientImportSelector.class) public @interface EnableDiscoveryClient { } EnableDiscoveryClient注解的作用主要是用来引入EnableDiscoveryClientImportSelector
EnableDiscoveryClientImportSelector
@Order(Ordered.LOWEST_PRECEDENCE - 100) public class EnableDiscoveryClientImportSelector extends SpringFactoryImportSelector&amp;lt;EnableDiscoveryClient&amp;gt; { @Override protected boolean isEnabled() { return new RelaxedPropertyResolver(getEnvironment()).</description></item><item><title>Kafka发送不同确认方式的性能差异</title><link>https://atbug.com/articles/kafka-producer-acknowledge-benchmark/</link><pubDate>Tue, 10 Oct 2017 11:49:58 +0000</pubDate><guid>https://atbug.com/articles/kafka-producer-acknowledge-benchmark/</guid><description>背景 Kafka的性能众所周知，Producer支持acknowledge模式。即Kafka会想Producer返回消息发送的结果。但是在Java Client中，acknowledge的确认有两种：同步和异步。 同步是通过调用future.get()实现的；异步则是通过提供callback方法来实现。写了个简单的程序测试一下单线程中吞吐差异能有多大。注意这里只考虑横向对比。
发送端单线程 Kafka为单集群节点 topic的分区数为1 key长度1 payload长度100 测试工具 JMeter Kafka Meter future.get() + batch size =1 future.get() + batch size = 16K callback + batch size = 16k callback + batch size = 1</description></item><item><title>Kafka 恰好一次发送和事务消费示例</title><link>https://atbug.com/articles/kafka-exactly-once-delivery-and-transactional-messaging-example/</link><pubDate>Fri, 22 Sep 2017 18:03:43 +0000</pubDate><guid>https://atbug.com/articles/kafka-exactly-once-delivery-and-transactional-messaging-example/</guid><description>核心思想 生产端一致性: 开启幂等和事务, 包含重试, 发送确认, 同一个连接的最大未确认请求数. 消费端一致性: 通过设置读已提交的数据和同时处理完成每一条消息之后手动提交offset. 生产端 public class ProducerTest { public static void main(String[] args) throws InterruptedException, ExecutionException { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &amp;#34;my-transactional-id&amp;#34;); props.put(ProducerConfig.ACKS_CONFIG, &amp;#34;all&amp;#34;); props.put(ProducerConfig.RETRIES_CONFIG, &amp;#34;3&amp;#34;); props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, &amp;#34;1&amp;#34;); Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props, new StringSerializer(), new StringSerializer()); producer.</description></item><item><title>Kafka Producer配置解读</title><link>https://atbug.com/articles/kafka-producer-config/</link><pubDate>Tue, 19 Sep 2017 15:38:03 +0000</pubDate><guid>https://atbug.com/articles/kafka-producer-config/</guid><description>按照重要性分类, 基于版本0.11.0.0
高 bootstrap.servers 一组host和port用于初始化连接. 不管这里配置了多少台server, 都只是用作发现整个集群全部server信息. 这个配置不需要包含集群所有的机器信息. 但是最好多于一个, 以防服务器挂掉.
key.serializer 用来序列化key的Serializer接口的实现类.
value.serializer 用来序列化value的Serializer接口的实现类
acks producer希望leader返回的用于确认请求完成的确认数量. 可选值 all, -1, 0 1. 默认值为1
acks=0 不需要等待服务器的确认. 这是retries设置无效. 响应里来自服务端的offset总是-1. producer只管发不管发送成功与否。延迟低，容易丢失数据。 acks=1 表示leader写入成功（但是并没有刷新到磁盘）后即向producer响应。延迟中等，一旦leader副本挂了，就会丢失数据。 acks=all等待数据完成副本的复制, 等同于-1. 假如需要保证消息不丢失, 需要使用该设置. 同时需要设置unclean.leader.election.enable为true, 保证当ISR列表为空时, 选择其他存活的副本作为新的leader. buffer.memory producer可以使用的最大内存来缓存等待发送到server端的消息. 如果消息速度大于producer交付到server端的阻塞时间max.</description></item><item><title>JSON Patch</title><link>https://atbug.com/articles/json-patch/</link><pubDate>Sun, 27 Aug 2017 14:41:44 +0000</pubDate><guid>https://atbug.com/articles/json-patch/</guid><description>JSON Path是在使用Kubernetes API的过程中首次使用的. 使用API做扩缩容的时候, 发送整个Deployment的全文不是个明智的做法, 虽然可行. 因此便使用了JSON Patch.
JsonObject item = new JsonObject(); item.add(&amp;#34;op&amp;#34;, new JsonPrimitive(&amp;#34;replace&amp;#34;)); item.add(&amp;#34;path&amp;#34;, new JsonPrimitive(&amp;#34;/spec/replicas&amp;#34;)); item.add(&amp;#34;value&amp;#34;, new JsonPrimitive(instances)); JsonArray body = new JsonArray(); body.add(item); appsV1beta1Api.patchNamespacedScaleScale(id, namespace, body, null); fabric8s提供的kubernetes-client中使用的zjsonpatch则封装了JSON Patch操作. 例如在做扩缩容的时候或者当前的deployment, 修改replicas的值. 然后比较对象的不同(JsonDiff.asJson(sourceJsonNode, targetJsonNode)).
下面的内容部分翻译自JSON PATH, 有兴趣的可以跳转看原文.</description></item><item><title>暴力停止ExecutorService的线程</title><link>https://atbug.com/articles/stop-a-thread-of-executor-service/</link><pubDate>Wed, 19 Jul 2017 22:25:19 +0000</pubDate><guid>https://atbug.com/articles/stop-a-thread-of-executor-service/</guid><description>停止，stop，这里说的是真的停止。如何优雅的结束，这里就不提了。
这里要用Thread.stop()。众所周知，stop()方法在JDK中是废弃的。
该方法天生是不安全的。使用thread.stop()停止一个线程，导致释放（解锁）所有该线程已经锁定的监视器（因沿堆栈向上传播的未检查异常ThreadDeath而解锁）。如果之前受这些监视器保护的任何对象处于不一致状态，则不一致状态的对象（受损对象）将对其他线程可见，这可能导致任意的行为。
有时候我们会有这种需求，不需要考虑线程执行到哪一步。一般这种情况是外部执行stop，比如执行业务的线程因为各种原因假死或者耗时较长，由于设计问题又无法响应优雅的停止指令。
现在大家在项目中都很少直接使用线程，而是通过concurrent包中的类来实现多线程，例如ExecutorService的各种实现类。
一个简单的停止线程的例子：
public class ExecutorServiceTest { public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newSingleThreadExecutor(); final AtomicReference&amp;lt;Thread&amp;gt; t = new AtomicReference&amp;lt;&amp;gt;(); Future&amp;lt;?&amp;gt; firstFuture = executor.submit(new Runnable() { public void run() { Thread currentThread = Thread.</description></item><item><title>私有构造函数捕获模式</title><link>https://atbug.com/articles/private-constructor-capture-idiom/</link><pubDate>Wed, 24 May 2017 06:50:44 +0000</pubDate><guid>https://atbug.com/articles/private-constructor-capture-idiom/</guid><description>《Java并发编程实践》的注解中有提到这一概念。
The private constructor exists to avoid the race condition that would occur if the copy constructor were implemented as this (p.x, p.y); this is an example of the private constructor capture idiom (Bloch and Gafter, 2005).
结合原文代码：</description></item><item><title>Docker 快速构建 Cassandra 和 Java 操作</title><link>https://atbug.com/articles/java-operate-cassandra-deployed-in-docker/</link><pubDate>Thu, 18 May 2017 23:33:24 +0000</pubDate><guid>https://atbug.com/articles/java-operate-cassandra-deployed-in-docker/</guid><description>搭建Cassandra 使用docker创建Cassandra，方便快捷
docker pull cassandra:latest docker run -d --name cassandra -p 9042:9042 cassandra docker exec -it cassandra bash 创建keyspace、table #cqlsh&amp;gt; #create keyspace CREATE KEYSPACE contacts WITH REPLICATION = { &amp;#39;class&amp;#39; : &amp;#39;SimpleStrategy&amp;#39;, &amp;#39;replication_factor&amp;#39; : 1 }; #use USE contacts; #create table CREATE TABLE contact ( id UUID, email TEXT PRIMARY KEY ); 查看表数据 cqlsh:contacts&amp;gt; SELECT * FROM contact; email | id -------+---- (0 rows) Java客户端 引入依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.</description></item><item><title>MetaspaceSize的坑</title><link>https://atbug.com/articles/java8-metaspace-size-issue/</link><pubDate>Thu, 13 Apr 2017 11:55:14 +0000</pubDate><guid>https://atbug.com/articles/java8-metaspace-size-issue/</guid><description>这几天生产上有台机器的Metaspace一直在告警，Metaspace使用达到了97%。使用-XX:MetaspaceSize=512m，告警也还在在持续，查看MC只有81536.0，显然这个参数没起作用。
也有人遇到类似的问题，并在openjdk上提过类似的bug，其实是一个注释的bug，最终在JDK-8151845中修复了。
Class metadata is deallocated when the corresponding Java class is unloaded. Java classes are unloaded as a result of garbage collection, and garbage collections may be induced in order to unload classes and deallocate class metadata. When the space committed for class metadata reaches a certain level (a high-water mark), a garbage collection is induced.</description></item><item><title>一个Tomcat类加载问题</title><link>https://atbug.com/articles/one-tomcat-class-load-issue/</link><pubDate>Wed, 12 Apr 2017 10:40:01 +0000</pubDate><guid>https://atbug.com/articles/one-tomcat-class-load-issue/</guid><description>背景 一个Tomcat实例中运行了三个应用，其中一个对接了Apereo的CAS系统。现在要求另外两个系统也对接CAS系统，问题就出现了：
应用启动后打开其中两个应用的任何一个，登录完成后系统都没有问题。唯独首选打开第三个，其他两个报错ClassNotFoundException: org.apache.xerces.parsers.SAXParser。
发现这个类来自xerces:xercesImpl:jar:2.6.2，使用mvn dependency:tree发现是被xom:xom:1.1简洁引用。
分析 CAS client jar中使用XMLReaderFactory创建XMLReader，首次创建会从classpath中查找META-INF/services/org.xml.sax.driver文件，这个文件里的内容是一个类的全名。比如xercesImpl中该文件的内容是org.apache.xerces.parsers.SAXParser。
找到之后会将类名保存在XMLReaderFactory的静态变量_clsFromJar，并标记不会再查找org.xml.sax.driver文件。找不到的话则使用com.sun.org.apache.xerces.internal.parsers.SAXParser类。
然后再使用当前线程的ContextClassLoader对类进行加载，这里的的ContextClassLoader是一个WebAppClassLoader的实例。
同时XMLReaderFactory类是被BootStrapClassLoader加载的，为三个应用共享。
Tomcat类记载机制 Tomcat中有四个位置可以存放Java类库：/commons、/server、/shared和各Web应用的WEB-INF/lib目录。
/commons目录中的类库可以被Tomcat和所有Web应用使用 /server目录中的类库只能被Tomcat使用 /shared目录中的可以被所有Web应用的使用，但是对Tomcat不可见 各Web应用的WEB-INF/lib目录中的类库则只能被该的应用使用
Tomcat的使用CommonClassLoader、CatalinaClassLoader、SharedClassLoader、WebAPPClassLoader加载对应目录中的类库。
Bootstrap、Extension、Application是虚拟机使用的系统类加载器。
类的加载使用双亲委派机制(Parent-Delegation)。
Bootstrap | Extension | Application | System | Common / \ Catalina Shared / \ WebApp1 .</description></item><item><title>Scala笔记：用函数字面量块调用高阶函数</title><link>https://atbug.com/articles/call-high-order-function-in-function-literal/</link><pubDate>Tue, 11 Apr 2017 10:15:15 +0000</pubDate><guid>https://atbug.com/articles/call-high-order-function-in-function-literal/</guid><description>这里会用到几个概念高阶函数、函数字面量、参数组
高阶函数 high-order function 函数的一种，简单来说它包含了一个函数类型的参数或者返回值。
所谓的高阶是跟一阶函数相比，深入一下：
一个或多个参数是函数，并返回一个值。 返回一个函数，但没有参数是函数。 上述两者叠加：一个或多个参数是函数，并返回一个函数。 示例：
def stringSafeOp(s: String, f: String =&amp;gt; String) = { if ( s != null) f(s) else s } //stringSafeOp: (s: String, f: String =&amp;gt; String)String def reverse(s: String) = s.</description></item><item><title>GreenPlum JDBC和C3P0数据源</title><link>https://atbug.com/articles/greenplum-jdbc-and-c3p0-datasource/</link><pubDate>Mon, 10 Apr 2017 08:29:00 +0000</pubDate><guid>https://atbug.com/articles/greenplum-jdbc-and-c3p0-datasource/</guid><description>在网上搜索GreenPlum（GPDB）的数据源配置的时候，发现搜索结果都是用postgresql的配置。
import com.mchange.v2.c3p0.DataSources; import javax.sql.DataSource; import java.sql.*; import java.util.Properties; /** * Created by addo on 2017/4/10. */ public class JDBCTest { private static String POSTGRESQL_URL = &amp;#34;jdbc:postgresql://192.168.56.101:5432/example&amp;#34;; private static String POSTGRESQL_USERNAME = &amp;#34;dbuser&amp;#34;; private static String POSTGRESQL_PASSWORD = &amp;#34;password&amp;#34;; private static String GPDB_URL = &amp;#34;jdbc:pivotal:greenplum://192.</description></item><item><title>Scala笔记：def VS val</title><link>https://atbug.com/articles/def-vs-val-in-scala/</link><pubDate>Sun, 09 Apr 2017 08:24:40 +0000</pubDate><guid>https://atbug.com/articles/def-vs-val-in-scala/</guid><description>先说原理： val修饰的在定义的时候执行
def修饰的在调用的时候执行
直观的例子： //注释的行为REPL输出 def test: () =&amp;gt; Int = { println(&amp;#34;def called&amp;#34;) val r = util.Random.nextInt () =&amp;gt; r } //test: () =&amp;gt; Int test() //def called //res82: Int = -950077410 test() //def called //res83: Int = 1027028032 val test: () =&amp;gt; Int = { println(&amp;#34;def called&amp;#34;) val r = util.</description></item><item><title>Key长度对Redis性能影响</title><link>https://atbug.com/articles/redis-performance-key-length/</link><pubDate>Thu, 16 Mar 2017 10:37:03 +0000</pubDate><guid>https://atbug.com/articles/redis-performance-key-length/</guid><description>最近Redis的使用中用的到key可能比较长，但是Redis的官方文档没提到key长度对性能的影响，故简单做了个测试。
环境 Redis和测试程序都是运行在本地，不看单次的性能，只看不同的长度堆读写性能的影响。
测试方法 使用长度分别为10, 100, 500, 1000, 2500, 5000, 7500, 10,000, and 20,000的key，value长度1000，读写1000次。
结果 从结果来看随着长度的增加，读写的耗时都随之增加。
长度为10：写平均耗时0.053ms，读0.040ms 长度为20000：写平均耗时0.352ms，读0.084ms 测试代码 源码
/** * Created by addo on 2017/3/16. */ public class RedisTest { private static String[] keys = new String[1000]; private static String randomString(int length) { Random random = new Random(); char[] chars = &amp;#34;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&amp;#34;.</description></item><item><title>遍历 Collection 时删除元素</title><link>https://atbug.com/articles/remove-element-while-looping-collection/</link><pubDate>Sun, 05 Mar 2017 22:04:58 +0000</pubDate><guid>https://atbug.com/articles/remove-element-while-looping-collection/</guid><description>其实标题我想用《为什么foreach边循环边移除元素要用Iterator？》可是太长。
不用Iterator，用Collection.remove()，会报ConcurrentModificationException错误。
for(Integer i : list) { list.remove(i); //Throw ConcurrentModificationException } 其实使用foreach的时候，会自动生成一个Iterator来遍历list。不只是remove，使用add、clear等方法一样会出错。
拿ArrayList来说，它有一个私有的Iterator接口的内部类Itr：
private class Itr implements Iterator&amp;lt;E&amp;gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; //sevrval methods } 使用Iterator来遍历ArrayList实际上是通过两个指针来遍历ArrayList底层的数组：cursor是下一个返回的元素在数组中的下标；lastRet是上一个元素的下标。还有一个重要的expectedModCount使用的是ArrayList的modCount的（modCount具体是什么意思下文会提到）。</description></item><item><title>Java Volatile关键字</title><link>https://atbug.com/articles/deep-in-java-volatile-keywork/</link><pubDate>Thu, 02 Mar 2017 08:30:29 +0000</pubDate><guid>https://atbug.com/articles/deep-in-java-volatile-keywork/</guid><description>volatile通过保证对变量的读或写都是直接从内存中读取或直接写入内存中，保证了可见性；但是volatile并不足以保证线程安全，因为无法保证原子性，如count++操作：
将值从内存读入寄存器中 进行加1操作，内存保存到寄存器中 结果从寄存器flush到内存中 借用一张图来看：
不是volatile的变量的指令执行顺序是1-&amp;gt;2-&amp;gt;3；而声明为volatile的变量，顺序是1-&amp;gt;23。从这里看，volatile保证了一个线程修改了volatile修饰的变量，变化会马上体现在内存中。线程间看到的值是一样的。
上面说了无法保证原子性是指：多核cpu，线程A执行了指令1，线程B也执行了指令1。A进行了加1操作，结果写入寄存器同时flush到内存；随后B也执行了同样的操作。count本来应该的结果是加2，但是却只加了1。原因就是我们通常所指的读和写不是原子操作。我们最希望看到的是123同时执行，手段就是sychronized或者java.util.concurrent包中的原子数据类型。
简单拿AtomicInteger来看，其中的一个int类型的value字段声明为volatile，保证了123同时执行。
参考：Java Volatile</description></item><item><title>mybatis报错“Result Maps collection already contains value for ***”</title><link>https://atbug.com/articles/duplicate-resultmap-in-mybatis-mapper/</link><pubDate>Wed, 22 Feb 2017 14:12:18 +0000</pubDate><guid>https://atbug.com/articles/duplicate-resultmap-in-mybatis-mapper/</guid><description>这是工作中遇到的一个问题：测试环境部署出错，报了下面的问题。
Caused by: java.lang.IllegalArgumentException: Result Maps collection already contains value for xxx.xxx.xxxRepository.BaseResultMap at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:802) at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:774) at org.apache.ibatis.session.Configuration.addResultMap(Configuration.java:556) at org.apache.ibatis.builder.MapperBuilderAssistant.addResultMap(MapperBuilderAssistant.java:217) at org.apache.ibatis.builder.ResultMapResolver.resolve(ResultMapResolver.java:47) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:285) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:252) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElements(XMLMapperBuilder.java:244) at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:116) 检查了对应的mapper文件和java文件，已经8个多月没有修改过了。也检查了内容，没有发现重复的BaseResultMap；select中也resultMap的引用也都正确。
其实到最后发现跟代码一丁点关系都没有，是部署的时候没有删除旧版本的代码导致两个不同版本的jar同时存在，相应的mapper文件也有两个。
看了下源码，mybatis在创建SessionFactoryBean解析xml时候，会把xml中的resultMap放入到一个HashMap的子类StrictMap中，key是mapper的namespace与resultmap的id拼接成的。
StrictMap在put元素的时候，会检查map中是否已存在key。
public void addResultMap(ResultMap rm) { resultMaps.put(rm.getId(), rm); checkLocallyForDiscriminatedNestedResultMaps(rm); checkGloballyForDiscriminatedNestedResultMaps(rm); }</description></item><item><title>消费时offset被重置导致重复消费</title><link>https://atbug.com/articles/offset-be-reset-when-consuming/</link><pubDate>Mon, 20 Feb 2017 13:23:49 +0000</pubDate><guid>https://atbug.com/articles/offset-be-reset-when-consuming/</guid><description>这是实际使用时遇到的问题：kafka api的版本是0.10，发现有重复消费问题；检查log后发现在commit offset的时候发生超时。
Auto offset commit failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.</description></item><item><title>TheadPoolExecutor源码分析</title><link>https://atbug.com/articles/threadpoolexecutor-sourcecode-analysis/</link><pubDate>Mon, 20 Feb 2017 09:56:07 +0000</pubDate><guid>https://atbug.com/articles/threadpoolexecutor-sourcecode-analysis/</guid><description>TheadPoolExecutor源码分析 ThreadPoolExecutor是多线程中经常用到的类，其使用一个线程池执行提交的任务。
实现 没有特殊需求的情况下，通常都是用Executors类的静态方法如newCachedThreadPoll来初始化ThreadPoolExecutor实例：
public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;()); } 从Executors的方法实现中看出，BlockingQueue使用的SynchronousQueue，底层使用了栈的实现。值得注意的是，这个SynchronousQueue是没有容量限制的，Executors也将maximumPoolSize设为Integer.MAX_VALUE。
ThreadPoolExecutor的构造方法：
按照javadoc的解释：
corePoolSize是池中闲置的最小线程数 maximumPoolSize是池中允许的最大线程数 keepAliveTime是线程数大于最小线程数时，过量闲置线程的最大存活时间 unit是上面存活时间的单位 workQueue是用来暂时保存运行前的任务 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue) public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.</description></item><item><title>Kafka Java生产者模型</title><link>https://atbug.com/articles/kafka-java-producer-model/</link><pubDate>Wed, 04 Jan 2017 16:33:02 +0000</pubDate><guid>https://atbug.com/articles/kafka-java-producer-model/</guid><description>Producer初始化 初始化KafkaProducer实例，同时通过Config数据初始化MetaData、NetWorkClient、Accumulator和Sender线程。启动Sender线程。
MetaData信息 记录Cluster的相关信息，第一次链接使用Config设置，之后会从远端poll信息回来，比如host.name等信息。
Accumulator实例 Accumulator持有一个Map实例，key为TopicPartition（封装了topic和partition信息）对象，Value为RecordBatch的Deque集合。
NetworkClient实例 通过MetaData信息初始化NetworkClient实例，NetworkClient使用NIO模型。
Sender线程 sender持有NetworkClient和Accumulator实例，在Producer实例初始化完成之后，持续地将Accumulator中的Batch数据drain到一个List中，调用NetworkClient进行发送。
发送 调用Producer实例进行消息发送，首先将消息序列化之后追加到Accumulator的Deque的最后一个batch中，之后唤醒sender-&amp;gt;client-&amp;gt;Selector进行消息发送。</description></item><item><title>Redis清理缓存</title><link>https://atbug.com/articles/clean-speicified-keys-in-redis/</link><pubDate>Tue, 13 Dec 2016 16:54:41 +0000</pubDate><guid>https://atbug.com/articles/clean-speicified-keys-in-redis/</guid><description>最近有个需求需要主动的去清理部分缓存，考虑的原子性的问题，用Lua脚本进行实现。
Lua脚本
local count = 0 for _,k in ipairs(redis.call(&amp;#39;KEYS&amp;#39;, ARGV[1])) do redis.call(&amp;#39;DEL&amp;#39;, k) count = count + 1 end return count shell运行
redis-cli --eval file.lua ,[KEY PATTERN] #sample: 清理所有key以Test开头的记录 redis-cli --eval clear.lua , Test* Java
Jedis jedis = new Jedis(&amp;#34;127.</description></item><item><title>探索Rabbitmq的Java客户端</title><link>https://atbug.com/articles/deep-in-rabbitmq-java-client/</link><pubDate>Sun, 09 Oct 2016 09:20:07 +0000</pubDate><guid>https://atbug.com/articles/deep-in-rabbitmq-java-client/</guid><description>AMQPConnection 实例初始化 创建Connection时会通过FrameHandlerFacotry创建一个SocketFrameHandler，SocketFrameHandler对Socket进行了封装。
public AMQConnection(ConnectionParams params, FrameHandler frameHandler) { checkPreconditions(); this.username = params.getUsername(); this.password = params.getPassword(); this._frameHandler = frameHandler; this._virtualHost = params.getVirtualHost(); this._exceptionHandler = params.getExceptionHandler(); this._clientProperties = new HashMap&amp;lt;String, Object&amp;gt;(params.getClientProperties()); this.requestedFrameMax = params.getRequestedFrameMax(); this.requestedChannelMax = params.getRequestedChannelMax(); this.requestedHeartbeat = params.getRequestedHeartbeat(); this.shutdownTimeout = params.</description></item><item><title>深入剖析 HashSet 和 HashMap 实现</title><link>https://atbug.com/articles/deep-in-implementation-of-hashset/</link><pubDate>Mon, 11 Jul 2016 14:57:16 +0000</pubDate><guid>https://atbug.com/articles/deep-in-implementation-of-hashset/</guid><description>HashSet是一个包含非重复元素的集合，如何实现的，要从底层实现代码看起。
背景 首先非重复元素如何定义，看Set的描述：
More formally, sets contain no pair of elements e1 and e2 such that e1.equals(e2), and at most one null element.
Set不会找到两个元素，并且两个元素满足e1.equals(e2)为true；并且最多只有一个null元素。
如果没有重写equals方法，查看Object类中equal方法的实现，==比较的其实是两个对象在内存中的地址。
public boolean equals(Object obj) { return (this == obj); } 说起equals方法，就不得不说hashCode方法了。Java中对于hashCode有个常规协定
The general contract of hashCode is:</description></item><item><title>多线程下的单例模式+反汇编</title><link>https://atbug.com/articles/singleton-in-multi-threads-programming/</link><pubDate>Wed, 06 Jul 2016 16:57:09 +0000</pubDate><guid>https://atbug.com/articles/singleton-in-multi-threads-programming/</guid><description>多线程下的单例模式的实现，顺便做了反汇编。
public class MySingleton { private static MySingleton INSTANCE; private MySingleton() { } public static MySingleton getInstance() { if (INSTANCE == null) { synchronized (MySingleton.class) { INSTANCE = new MySingleton(); } } return INSTANCE; } } Compiled from &amp;#34;MySingleton.java&amp;#34; public class MySingleton { public static MySingleton getInstance(); Code: 0: getstatic #2 // Field INSTANCE:LMySingleton; //+获得类的指定域，并压入栈顶 3: ifnonnull 32 //+不为null时跳转到行号32 6: ldc_w #3 // class MySingleton //+常量值从常量池中推送至栈顶（宽索引），推送的为地址 9: dup //+复制栈顶数值，并且复制值进栈 10: astore_0 //+将栈顶数值（objectref）存入当前 frame的局部变量数组中指定下标(index）处的变量中，栈顶数值出栈。这里存的是MySingleton类定义的地址 11: monitorenter //+获得对象锁即MySingleton地址 12: new #3 // class MySingleton //+创建一个对象，并且其引用进栈 15: dup //+复制栈顶数值，并且复制值进栈 16: invokespecial #4 // Method &amp;#34;&amp;lt;init&amp;gt;&amp;#34;:()V //+调用超类构造方法、实例初始化方法、私有方法 19: putstatic #2 // Field INSTANCE:LMySingleton; //+为指定的类的静态域赋值 22: aload_0 //+当前frame的局部变量数组中下标为 index的引用型局部变量进栈，这里是MySingleton类定义的地址 23: monitorexit //+释放对象锁 24: goto 32 //+跳转到行号32 27: astore_1 //+将栈顶数值（objectref）存入当前 frame的局部变量数组中指定下标(index）处的变量中，栈顶数值出栈。 28: aload_0 //+当前frame的局部变量数组中下标为 0的引用型局部变量进栈 29: monitorexit //+//+释放对象锁 30: aload_1 //+当前frame的局部变量数组中下标为 1的引用型局部变量进栈 31: athrow //+将栈顶的数值作为异常或错误抛出 32: getstatic #2 // Field INSTANCE:LMySingleton; //+获得类的指定域，并压入栈顶 35: areturn //+从方法中返回一个对象的引用 Exception table: from to target type 12 24 27 any 27 30 27 any }</description></item><item><title>使用Kryo替换spring amqp的Java序列化</title><link>https://atbug.com/articles/use-kryo-in-spring-amqp-serialization/</link><pubDate>Wed, 29 Jun 2016 05:29:14 +0000</pubDate><guid>https://atbug.com/articles/use-kryo-in-spring-amqp-serialization/</guid><description>spring amqp的原生并没有对Kryo加以支持，Kryo的优点就不多说了。
git地址：https://github.com/addozhang/spring-kryo-messaeg-converter
public class KryoMessageConverter extends AbstractMessageConverter { public static final String CONTENT_TYPE = &amp;#34;application/x-kryo&amp;#34;; public static final String DEFAULT_CHARSET = &amp;#34;UTF-8&amp;#34;; private String defaultCharset = DEFAULT_CHARSET; private KryoFactory kryoFactory = new DefaultKryoFactory(); /** * Crate a message from the payload object and message properties provided.</description></item><item><title>Rabbitmq延迟队列实现</title><link>https://atbug.com/articles/rabbitmq-delay-queue-implementation/</link><pubDate>Wed, 30 Mar 2016 14:27:02 +0000</pubDate><guid>https://atbug.com/articles/rabbitmq-delay-queue-implementation/</guid><description>工作中很多场景需要用到定时任务、延迟任务，常用的方法用crontab job、Spring的Quartz，然后扫描整张数据库表，判断哪些数据需要处理。控制的粒度没办法做到特定数据上。 后来就想到了Rabbitmq，Rabbitmq本来不没有延迟队列的功能，但是有个[Dead Letter Exchange](https://www.rabbitmq.com/dlx.html)功能。 DLX是指队列中的消息在下面几种情况下会变为死信（dead letter），然后会被发布到另一个exchange中。 在requeue=false的情况系，消息被client reject 消息过期 队列长度超过限制 有了DLX，就可以将需要延迟的操作设置下次执行时间（如消息的TTL时间）放入一个存储队列中，消息过期后会经由DLX进入监听的队列中。有消费方进行相关的操作，结束或者再次进入存储队列中。 Spring AMQP实现 Configuration: &amp;lt;rabbit:connection-factory id="rabbitMQConnectionFactory" requested-heartbeat="" host="${rabbit.host}" port="${rabbit.port}" username="${rabbit.username}" password="${rabbit.password}" publisher-confirms="true" channel-cache-size="10"/&amp;gt; &amp;lt;rabbit:admin connection-factory="rabbitMQConnectionFactory"/&amp;gt; &amp;lt;!--声明延时队列--&amp;gt; &amp;lt;rabbit:queue id="delayQueue" name="${rabbit.tracking.no.pre.track.delay.queue}"&amp;gt; &amp;lt;rabbit:queue-arguments&amp;gt; &amp;lt;entry key="</description></item><item><title>关于SLF4J</title><link>https://atbug.com/articles/about-slf4j/</link><pubDate>Sat, 18 Apr 2015 11:16:26 +0000</pubDate><guid>https://atbug.com/articles/about-slf4j/</guid><description>Spring的功能越来越强大，同时也越来越臃肿。比如想快速搭建一个基于Spring的项目，解决依赖问题非常耗时。Spring的项目模板的出现就解决了这个问题，通过这个描述文件，可以快速的找到你所需要的模板。
第一次认识SLF4J就是在这些项目模板里，它的全称是Simple Logging Facade for Java。从字面上可以看出它只是一个Facade，不提供具体的日志解决方案，只服务于各个日志系统。简单说有了它，我们就可以随意的更换日志系统（如java.util.logging、logback、log4j）。比如在开发的时候使用logback，部署的时候可以切换到log4j；如果关闭所有的log，切换到NOP就可以了。只需要更改依赖，提供日志配置文件，免去了修改代码的麻烦。
首先看如何使用：
[java] import org.slf4j.Logger; import org.slf4j.LoggerFactory;
public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(&amp;quot;Hello World&amp;quot;); } } [/java]
SLF4J封装了使用起来和其他日志系统一样简单。上面提到过SLF4J不提供具体的日志解决方案，所以使用的时候除了要引用SLF4J包，还要引用具体的日志解决方案包（log4j、logging&amp;ndash;JDK提供、logback），还有所对应的binding包（slf4j-log4j_、slf4j-jdk14、logback-classic_）。
以log4j为例，我们看SLF4J的实现方式。
SLF4J类在初始化的时候会尝试从ClassLoader中org/slf4j/impl/StaticLoggerBinder.class。这个类比较特殊，每个binding包里都有。不同binding包里的StaticLoggerBinder类会去初始化一个相应的实例，如slf4j-log4j里：
[java] /**
截取的部分代码 */ private StaticLoggerBinder() { loggerFactory = new Log4jLoggerFactory(); } [/java] 而Log4jLoggerAdapter实现了SLF4J的Logger接口，使用了Adapter模式对Log4j的Logger进行了封装并暴露了Logger的接口，Log4jLoggerFactory持有了Log4jLoggerAdapter的实例。</description></item></channel></rss>