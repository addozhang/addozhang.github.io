<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java on 乱世浮生</title><link>https://atbug.com/tags/java/</link><description>Recent content in Java on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 27 Jan 2022 11:07:34 +0800</lastBuildDate><atom:link href="https://atbug.com/tags/java/index.xml" rel="self" type="application/rss+xml"/><item><title>使用 sdkman 在 M1 Mac 上 安装 graalvm jdk</title><link>https://atbug.com/articles/install-graalvm-on-m1-mac-with-sdkman/</link><pubDate>Thu, 27 Jan 2022 11:07:34 +0800</pubDate><guid>https://atbug.com/articles/install-graalvm-on-m1-mac-with-sdkman/</guid><description>&lt;p>SDKMAN 是一款管理多版本 SDK 的工具，可以实现在多个版本间的快速切换。安装和使用非常简单：&lt;/p></description></item><item><title>应“云”而生的 Java 框架：构建本机可执行文件</title><link>https://atbug.com/articles/quarkus-build-native-executable-file/</link><pubDate>Sat, 17 Apr 2021 09:08:40 +0800</pubDate><guid>https://atbug.com/articles/quarkus-build-native-executable-file/</guid><description>电影《功夫》中，火云邪神有句话：“天下武功无坚不摧，唯快不破。”
在 上一篇文章 中，我们写了第一个 Quarkus 应用，并尝试着构建了 legacy-jar 和 fast-jar。
今天来看一下 Quarkus 构建出来的本机可执行文件到底比 Spring 应用能快多少，生态的成熟度不在这里讨论。
TLDR 先上结论， 与只有一个 Controller 的Spring Web 应用做下对比。
应用启动时间：0.012s vs 2.294s 镜像大小：49MB vs 237 MB Spring 应用镜像使用 openjdk:11.0-jre-slim 作为 base 镜像，大小为 220MB。
docker images REPOSITORY TAG IMAGE ID CREATED SIZE spring/spring-getting-started latest 5f47030c5c3f 6 minutes ago 237MB quarkus/quarkus-getting-started distroless2 fe973c5ac172 24 minutes ago 49MB quarkus/quarkus-getting-started distroless 6fe27dd44e86 31 minutes ago 51MB quarkus/quarkus-getting-started ubi 8f86f5915715 58 minutes ago 132MB Java 应用容器化的困境 云原生世界中，应用容器化是个显著的特点。Java 应用容器化时面临了如下问题：</description></item><item><title>应“云”而生的 Java 框架：Hello, Quarkus</title><link>https://atbug.com/articles/hello-quarkus/</link><pubDate>Mon, 05 Apr 2021 21:08:40 +0800</pubDate><guid>https://atbug.com/articles/hello-quarkus/</guid><description>Wikipedia上有关 Quarkus 的信息还很少，只有一句简单的介绍：
Quarkus 是专为 OpenJDK HotSpot 和 GraalVM 定制的全栈 Kubernetes 原生 Java 应用程序框架。与如 Spring 之类的其他框架相比，它提供了较小的内存占用并缩短了启动时间。它允许结合命令式和非阻塞响应式编程。
从 Quarkus 的官网，可以看到其有几个特性：
容器优先 统一了命令式和响应式编程 开发者友好 最佳品种的库及标准 更多 Quarkus 可以参考官网的介绍及文档。今天主要就是跑一下 Quarkus 的 Hello world。
放一张官网的图：
环境准备 基于 Java 11 的 GraalVM Maven 3.</description></item><item><title>Java 中的 Mysql 时区问题</title><link>https://atbug.com/articles/mysql-timezone-in-java/</link><pubDate>Thu, 14 May 2020 11:34:24 +0800</pubDate><guid>https://atbug.com/articles/mysql-timezone-in-java/</guid><description>(Photo by Andrea Piacquadio from Pexels)
话说工作十多年，mysql 还真没用几年。起初是外企银行，无法直接接触到 DB；后来一直从事架构方面，也多是解决问题为主。
这次搭建海外机房，围绕时区大家做了一番讨论。不说最终的结果是什么，期间有同事认为 DB 返回的是 UTC 时间。
这里简单做个验证，顺便看下时区的问题到底是如何处理。
环境 openjdk version &amp;ldquo;1.8.0_242&amp;rdquo; mysql-connector-java &amp;ldquo;8.0.20&amp;rdquo; mysql &amp;ldquo;5.7&amp;rdquo; 时区 TZ=Europe/London 本地时区 GMT+8
创建个简单的库test及表user， 表结构如下：
CREATE TABLE `user` ( `name` varchar(50) NOT NULL, `birth_date` timestamp NULL DEFAULT CURRENT_TIMESTAMP ) ENGINE=InnoDB DEFAULT CHARSET=latin1 插入一条测试数据：</description></item><item><title>加速云原生的 Java 开发</title><link>https://atbug.com/articles/speed-up-java-development-on-kubernetes/</link><pubDate>Sat, 21 Dec 2019 20:45:22 +0800</pubDate><guid>https://atbug.com/articles/speed-up-java-development-on-kubernetes/</guid><description>今天来说说日常在Kubernetes开发Java项目遇到的问题.
当我们新建一个项目的时候, 总是面临需要新建manifest, 平时都是copy+paste+modify. 能否以变成的方式来生成?
开发时的步骤也比较繁琐: docker build, docker push, kubectl apple, kubectl delete pod. 对于一个Java应用来说还多了一步编译. 操作一次还ok, 但是一天十几次总会有想吐的感觉. 这些步骤能否简化成一个命令, 甚至修改了代码自动就完成上面一系列的操作?
实现这些我们需要几个工具: dekorate, Jib, Skaffold. 其中Jib也在上一篇文章使用Jib为Java应用构建镜像中介绍过.
dekorate Dekorate is a collection of Java compile-time generators and decorators for Kubernetes/OpenShift manifests. Dekorate是Java编译时生成和装饰Kubernetes/OpenShift的manifests的工具</description></item><item><title>SpringBoot源码 - 启动</title><link>https://atbug.com/articles/glance-over-spring-boot-source/</link><pubDate>Fri, 08 Dec 2017 17:48:43 +0000</pubDate><guid>https://atbug.com/articles/glance-over-spring-boot-source/</guid><description>SpringBoot Application启动部分的源码阅读.
SpringApplication 常用的SpringApplication.run(Class, Args)启动Spring应用, 创建或者更新ApplicationContext
静态方法run 使用source类实例化一个SpringApplication实例, 并调用实例方法run.
public static ConfigurableApplicationContext run(Object[] sources, String[] args) { return new SpringApplication(sources).run(args); } 初始化initialize 实例化的时候首先通过尝试加载javax.servlet.Servlet和org.springframework.web.context.ConfigurableWebApplicationContext推断当前是否是web环境.
然后从spring.factories获取ApplicationContextInitializer的实现类.
从spring.factories获取ApplicationListener的实现类
推断出应用的启动类(包含main方法的类): 检查线程栈中元素的方法名是否是main
private Class&amp;lt;?&amp;gt; deduceMainApplicationClass() { try { //获取线程栈数据 StackTraceElement[] stackTrace = new RuntimeException().</description></item><item><title>Kafka 恰好一次发送和事务消费示例</title><link>https://atbug.com/articles/kafka-exactly-once-delivery-and-transactional-messaging-example/</link><pubDate>Fri, 22 Sep 2017 18:03:43 +0000</pubDate><guid>https://atbug.com/articles/kafka-exactly-once-delivery-and-transactional-messaging-example/</guid><description>核心思想 生产端一致性: 开启幂等和事务, 包含重试, 发送确认, 同一个连接的最大未确认请求数. 消费端一致性: 通过设置读已提交的数据和同时处理完成每一条消息之后手动提交offset. 生产端 public class ProducerTest { public static void main(String[] args) throws InterruptedException, ExecutionException { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;#34;192.168.31.186:9092&amp;#34;); props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &amp;#34;my-transactional-id&amp;#34;); props.put(ProducerConfig.ACKS_CONFIG, &amp;#34;all&amp;#34;); props.put(ProducerConfig.RETRIES_CONFIG, &amp;#34;3&amp;#34;); props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, &amp;#34;1&amp;#34;); Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props, new StringSerializer(), new StringSerializer()); producer.</description></item><item><title>暴力停止ExecutorService的线程</title><link>https://atbug.com/articles/stop-a-thread-of-executor-service/</link><pubDate>Wed, 19 Jul 2017 22:25:19 +0000</pubDate><guid>https://atbug.com/articles/stop-a-thread-of-executor-service/</guid><description>停止，stop，这里说的是真的停止。如何优雅的结束，这里就不提了。
这里要用Thread.stop()。众所周知，stop()方法在JDK中是废弃的。
该方法天生是不安全的。使用thread.stop()停止一个线程，导致释放（解锁）所有该线程已经锁定的监视器（因沿堆栈向上传播的未检查异常ThreadDeath而解锁）。如果之前受这些监视器保护的任何对象处于不一致状态，则不一致状态的对象（受损对象）将对其他线程可见，这可能导致任意的行为。
有时候我们会有这种需求，不需要考虑线程执行到哪一步。一般这种情况是外部执行stop，比如执行业务的线程因为各种原因假死或者耗时较长，由于设计问题又无法响应优雅的停止指令。
现在大家在项目中都很少直接使用线程，而是通过concurrent包中的类来实现多线程，例如ExecutorService的各种实现类。
一个简单的停止线程的例子：
public class ExecutorServiceTest { public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newSingleThreadExecutor(); final AtomicReference&amp;lt;Thread&amp;gt; t = new AtomicReference&amp;lt;&amp;gt;(); Future&amp;lt;?&amp;gt; firstFuture = executor.submit(new Runnable() { public void run() { Thread currentThread = Thread.</description></item><item><title>私有构造函数捕获模式</title><link>https://atbug.com/articles/private-constructor-capture-idiom/</link><pubDate>Wed, 24 May 2017 06:50:44 +0000</pubDate><guid>https://atbug.com/articles/private-constructor-capture-idiom/</guid><description>《Java并发编程实践》的注解中有提到这一概念。
The private constructor exists to avoid the race condition that would occur if the copy constructor were implemented as this (p.x, p.y); this is an example of the private constructor capture idiom (Bloch and Gafter, 2005).
结合原文代码：</description></item><item><title>Docker快速构建Cassandra和Java操作</title><link>https://atbug.com/articles/java-operate-cassandra-deployed-in-docker/</link><pubDate>Thu, 18 May 2017 23:33:24 +0000</pubDate><guid>https://atbug.com/articles/java-operate-cassandra-deployed-in-docker/</guid><description>搭建Cassandra 使用docker创建Cassandra，方便快捷
docker pull cassandra:latest docker run -d --name cassandra -p 9042:9042 cassandra docker exec -it cassandra bash 创建keyspace、table #cqlsh&amp;gt; #create keyspace CREATE KEYSPACE contacts WITH REPLICATION = { &amp;#39;class&amp;#39; : &amp;#39;SimpleStrategy&amp;#39;, &amp;#39;replication_factor&amp;#39; : 1 }; #use USE contacts; #create table CREATE TABLE contact ( id UUID, email TEXT PRIMARY KEY ); 查看表数据 cqlsh:contacts&amp;gt; SELECT * FROM contact; email | id -------+---- (0 rows) Java客户端 引入依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.</description></item><item><title>MetaspaceSize的坑</title><link>https://atbug.com/articles/java8-metaspace-size-issue/</link><pubDate>Thu, 13 Apr 2017 11:55:14 +0000</pubDate><guid>https://atbug.com/articles/java8-metaspace-size-issue/</guid><description>这几天生产上有台机器的Metaspace一直在告警，Metaspace使用达到了97%。使用-XX:MetaspaceSize=512m，告警也还在在持续，查看MC只有81536.0，显然这个参数没起作用。
也有人遇到类似的问题，并在openjdk上提过类似的bug，其实是一个注释的bug，最终在JDK-8151845中修复了。
Class metadata is deallocated when the corresponding Java class is unloaded. Java classes are unloaded as a result of garbage collection, and garbage collections may be induced in order to unload classes and deallocate class metadata. When the space committed for class metadata reaches a certain level (a high-water mark), a garbage collection is induced.</description></item><item><title>一个Tomcat类加载问题</title><link>https://atbug.com/articles/one-tomcat-class-load-issue/</link><pubDate>Wed, 12 Apr 2017 10:40:01 +0000</pubDate><guid>https://atbug.com/articles/one-tomcat-class-load-issue/</guid><description>背景 一个Tomcat实例中运行了三个应用，其中一个对接了Apereo的CAS系统。现在要求另外两个系统也对接CAS系统，问题就出现了：
应用启动后打开其中两个应用的任何一个，登录完成后系统都没有问题。唯独首选打开第三个，其他两个报错ClassNotFoundException: org.apache.xerces.parsers.SAXParser。
发现这个类来自xerces:xercesImpl:jar:2.6.2，使用mvn dependency:tree发现是被xom:xom:1.1简洁引用。
分析 CAS client jar中使用XMLReaderFactory创建XMLReader，首次创建会从classpath中查找META-INF/services/org.xml.sax.driver文件，这个文件里的内容是一个类的全名。比如xercesImpl中该文件的内容是org.apache.xerces.parsers.SAXParser。
找到之后会将类名保存在XMLReaderFactory的静态变量_clsFromJar，并标记不会再查找org.xml.sax.driver文件。找不到的话则使用com.sun.org.apache.xerces.internal.parsers.SAXParser类。
然后再使用当前线程的ContextClassLoader对类进行加载，这里的的ContextClassLoader是一个WebAppClassLoader的实例。
同时XMLReaderFactory类是被BootStrapClassLoader加载的，为三个应用共享。
Tomcat类记载机制 Tomcat中有四个位置可以存放Java类库：/commons、/server、/shared和各Web应用的WEB-INF/lib目录。
/commons目录中的类库可以被Tomcat和所有Web应用使用 /server目录中的类库只能被Tomcat使用 /shared目录中的可以被所有Web应用的使用，但是对Tomcat不可见 各Web应用的WEB-INF/lib目录中的类库则只能被该的应用使用
Tomcat的使用CommonClassLoader、CatalinaClassLoader、SharedClassLoader、WebAPPClassLoader加载对应目录中的类库。
Bootstrap、Extension、Application是虚拟机使用的系统类加载器。
类的加载使用双亲委派机制(Parent-Delegation)。
Bootstrap | Extension | Application | System | Common / \ Catalina Shared / \ WebApp1 .</description></item><item><title>GreenPlum JDBC和C3P0数据源</title><link>https://atbug.com/articles/greenplum-jdbc-and-c3p0-datasource/</link><pubDate>Mon, 10 Apr 2017 08:29:00 +0000</pubDate><guid>https://atbug.com/articles/greenplum-jdbc-and-c3p0-datasource/</guid><description>在网上搜索GreenPlum（GPDB）的数据源配置的时候，发现搜索结果都是用postgresql的配置。
import com.mchange.v2.c3p0.DataSources; import javax.sql.DataSource; import java.sql.*; import java.util.Properties; /** * Created by addo on 2017/4/10. */ public class JDBCTest { private static String POSTGRESQL_URL = &amp;#34;jdbc:postgresql://192.168.56.101:5432/example&amp;#34;; private static String POSTGRESQL_USERNAME = &amp;#34;dbuser&amp;#34;; private static String POSTGRESQL_PASSWORD = &amp;#34;password&amp;#34;; private static String GPDB_URL = &amp;#34;jdbc:pivotal:greenplum://192.</description></item><item><title>Key长度对Redis性能影响</title><link>https://atbug.com/articles/redis-performance-key-length/</link><pubDate>Thu, 16 Mar 2017 10:37:03 +0000</pubDate><guid>https://atbug.com/articles/redis-performance-key-length/</guid><description>最近Redis的使用中用的到key可能比较长，但是Redis的官方文档没提到key长度对性能的影响，故简单做了个测试。
环境 Redis和测试程序都是运行在本地，不看单次的性能，只看不同的长度堆读写性能的影响。
测试方法 使用长度分别为10, 100, 500, 1000, 2500, 5000, 7500, 10,000, and 20,000的key，value长度1000，读写1000次。
结果 从结果来看随着长度的增加，读写的耗时都随之增加。
长度为10：写平均耗时0.053ms，读0.040ms 长度为20000：写平均耗时0.352ms，读0.084ms 测试代码 源码
/** * Created by addo on 2017/3/16. */ public class RedisTest { private static String[] keys = new String[1000]; private static String randomString(int length) { Random random = new Random(); char[] chars = &amp;#34;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&amp;#34;.</description></item><item><title>遍历Collection时删除元素</title><link>https://atbug.com/articles/remove-element-while-looping-collection/</link><pubDate>Sun, 05 Mar 2017 22:04:58 +0000</pubDate><guid>https://atbug.com/articles/remove-element-while-looping-collection/</guid><description>其实标题我想用《为什么foreach边循环边移除元素要用Iterator？》可是太长。
不用Iterator，用Collection.remove()，会报ConcurrentModificationException错误。
for(Integer i : list) { list.remove(i); //Throw ConcurrentModificationException } 其实使用foreach的时候，会自动生成一个Iterator来遍历list。不只是remove，使用add、clear等方法一样会出错。
拿ArrayList来说，它有一个私有的Iterator接口的内部类Itr：
private class Itr implements Iterator&amp;lt;E&amp;gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; //sevrval methods } 使用Iterator来遍历ArrayList实际上是通过两个指针来遍历ArrayList底层的数组：cursor是下一个返回的元素在数组中的下标；lastRet是上一个元素的下标。还有一个重要的expectedModCount使用的是ArrayList的modCount的（modCount具体是什么意思下文会提到）。</description></item><item><title>Java Volatile关键字</title><link>https://atbug.com/articles/deep-in-java-volatile-keywork/</link><pubDate>Thu, 02 Mar 2017 08:30:29 +0000</pubDate><guid>https://atbug.com/articles/deep-in-java-volatile-keywork/</guid><description>volatile通过保证对变量的读或写都是直接从内存中读取或直接写入内存中，保证了可见性；但是volatile并不足以保证线程安全，因为无法保证原子性，如count++操作：
将值从内存读入寄存器中 进行加1操作，内存保存到寄存器中 结果从寄存器flush到内存中 借用一张图来看：
不是volatile的变量的指令执行顺序是1-&amp;gt;2-&amp;gt;3；而声明为volatile的变量，顺序是1-&amp;gt;23。从这里看，volatile保证了一个线程修改了volatile修饰的变量，变化会马上体现在内存中。线程间看到的值是一样的。
上面说了无法保证原子性是指：多核cpu，线程A执行了指令1，线程B也执行了指令1。A进行了加1操作，结果写入寄存器同时flush到内存；随后B也执行了同样的操作。count本来应该的结果是加2，但是却只加了1。原因就是我们通常所指的读和写不是原子操作。我们最希望看到的是123同时执行，手段就是sychronized或者java.util.concurrent包中的原子数据类型。
简单拿AtomicInteger来看，其中的一个int类型的value字段声明为volatile，保证了123同时执行。
参考：Java Volatile</description></item><item><title>mybatis报错“Result Maps collection already contains value for ***”</title><link>https://atbug.com/articles/duplicate-resultmap-in-mybatis-mapper/</link><pubDate>Wed, 22 Feb 2017 14:12:18 +0000</pubDate><guid>https://atbug.com/articles/duplicate-resultmap-in-mybatis-mapper/</guid><description>这是工作中遇到的一个问题：测试环境部署出错，报了下面的问题。
Caused by: java.lang.IllegalArgumentException: Result Maps collection already contains value for xxx.xxx.xxxRepository.BaseResultMap at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:802) at org.apache.ibatis.session.Configuration$StrictMap.put(Configuration.java:774) at org.apache.ibatis.session.Configuration.addResultMap(Configuration.java:556) at org.apache.ibatis.builder.MapperBuilderAssistant.addResultMap(MapperBuilderAssistant.java:217) at org.apache.ibatis.builder.ResultMapResolver.resolve(ResultMapResolver.java:47) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:285) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElement(XMLMapperBuilder.java:252) at org.apache.ibatis.builder.xml.XMLMapperBuilder.resultMapElements(XMLMapperBuilder.java:244) at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java:116) 检查了对应的mapper文件和java文件，已经8个多月没有修改过了。也检查了内容，没有发现重复的BaseResultMap；select中也resultMap的引用也都正确。
其实到最后发现跟代码一丁点关系都没有，是部署的时候没有删除旧版本的代码导致两个不同版本的jar同时存在，相应的mapper文件也有两个。
看了下源码，mybatis在创建SessionFactoryBean解析xml时候，会把xml中的resultMap放入到一个HashMap的子类StrictMap中，key是mapper的namespace与resultmap的id拼接成的。
StrictMap在put元素的时候，会检查map中是否已存在key。
public void addResultMap(ResultMap rm) { resultMaps.put(rm.getId(), rm); checkLocallyForDiscriminatedNestedResultMaps(rm); checkGloballyForDiscriminatedNestedResultMaps(rm); }</description></item><item><title>消费时offset被重置导致重复消费</title><link>https://atbug.com/articles/offset-be-reset-when-consuming/</link><pubDate>Mon, 20 Feb 2017 13:23:49 +0000</pubDate><guid>https://atbug.com/articles/offset-be-reset-when-consuming/</guid><description>这是实际使用时遇到的问题：kafka api的版本是0.10，发现有重复消费问题；检查log后发现在commit offset的时候发生超时。
Auto offset commit failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.</description></item><item><title>TheadPoolExecutor源码分析</title><link>https://atbug.com/articles/threadpoolexecutor-sourcecode-analysis/</link><pubDate>Mon, 20 Feb 2017 09:56:07 +0000</pubDate><guid>https://atbug.com/articles/threadpoolexecutor-sourcecode-analysis/</guid><description>TheadPoolExecutor源码分析 ThreadPoolExecutor是多线程中经常用到的类，其使用一个线程池执行提交的任务。
实现 没有特殊需求的情况下，通常都是用Executors类的静态方法如newCachedThreadPoll来初始化ThreadPoolExecutor实例：
public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;()); } 从Executors的方法实现中看出，BlockingQueue使用的SynchronousQueue，底层使用了栈的实现。值得注意的是，这个SynchronousQueue是没有容量限制的，Executors也将maximumPoolSize设为Integer.MAX_VALUE。
ThreadPoolExecutor的构造方法：
按照javadoc的解释：
corePoolSize是池中闲置的最小线程数 maximumPoolSize是池中允许的最大线程数 keepAliveTime是线程数大于最小线程数时，过量闲置线程的最大存活时间 unit是上面存活时间的单位 workQueue是用来暂时保存运行前的任务 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue) public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.</description></item><item><title>Kafka Java生产者模型</title><link>https://atbug.com/articles/kafka-java-producer-model/</link><pubDate>Wed, 04 Jan 2017 16:33:02 +0000</pubDate><guid>https://atbug.com/articles/kafka-java-producer-model/</guid><description>Producer初始化 初始化KafkaProducer实例，同时通过Config数据初始化MetaData、NetWorkClient、Accumulator和Sender线程。启动Sender线程。
MetaData信息 记录Cluster的相关信息，第一次链接使用Config设置，之后会从远端poll信息回来，比如host.name等信息。
Accumulator实例 Accumulator持有一个Map实例，key为TopicPartition（封装了topic和partition信息）对象，Value为RecordBatch的Deque集合。
NetworkClient实例 通过MetaData信息初始化NetworkClient实例，NetworkClient使用NIO模型。
Sender线程 sender持有NetworkClient和Accumulator实例，在Producer实例初始化完成之后，持续地将Accumulator中的Batch数据drain到一个List中，调用NetworkClient进行发送。
发送 调用Producer实例进行消息发送，首先将消息序列化之后追加到Accumulator的Deque的最后一个batch中，之后唤醒sender-&amp;gt;client-&amp;gt;Selector进行消息发送。</description></item><item><title>Redis清理缓存</title><link>https://atbug.com/articles/clean-speicified-keys-in-redis/</link><pubDate>Tue, 13 Dec 2016 16:54:41 +0000</pubDate><guid>https://atbug.com/articles/clean-speicified-keys-in-redis/</guid><description>最近有个需求需要主动的去清理部分缓存，考虑的原子性的问题，用Lua脚本进行实现。
Lua脚本
local count = 0 for _,k in ipairs(redis.call(&amp;#39;KEYS&amp;#39;, ARGV[1])) do redis.call(&amp;#39;DEL&amp;#39;, k) count = count + 1 end return count shell运行
redis-cli --eval file.lua ,[KEY PATTERN] #sample: 清理所有key以Test开头的记录 redis-cli --eval clear.lua , Test* Java
Jedis jedis = new Jedis(&amp;#34;127.</description></item><item><title>探索Rabbitmq的Java客户端</title><link>https://atbug.com/articles/deep-in-rabbitmq-java-client/</link><pubDate>Sun, 09 Oct 2016 09:20:07 +0000</pubDate><guid>https://atbug.com/articles/deep-in-rabbitmq-java-client/</guid><description>AMQPConnection 实例初始化 创建Connection时会通过FrameHandlerFacotry创建一个SocketFrameHandler，SocketFrameHandler对Socket进行了封装。
public AMQConnection(ConnectionParams params, FrameHandler frameHandler) { checkPreconditions(); this.username = params.getUsername(); this.password = params.getPassword(); this._frameHandler = frameHandler; this._virtualHost = params.getVirtualHost(); this._exceptionHandler = params.getExceptionHandler(); this._clientProperties = new HashMap&amp;lt;String, Object&amp;gt;(params.getClientProperties()); this.requestedFrameMax = params.getRequestedFrameMax(); this.requestedChannelMax = params.getRequestedChannelMax(); this.requestedHeartbeat = params.getRequestedHeartbeat(); this.shutdownTimeout = params.</description></item><item><title>深入剖析HashSet和HashMap实现</title><link>https://atbug.com/articles/deep-in-implementation-of-hashset/</link><pubDate>Mon, 11 Jul 2016 14:57:16 +0000</pubDate><guid>https://atbug.com/articles/deep-in-implementation-of-hashset/</guid><description>HashSet是一个包含非重复元素的集合，如何实现的，要从底层实现代码看起。
背景 首先非重复元素如何定义，看Set的描述：
More formally, sets contain no pair of elements e1 and e2 such that e1.equals(e2), and at most one null element.
Set不会找到两个元素，并且两个元素满足e1.equals(e2)为true；并且最多只有一个null元素。
如果没有重写equals方法，查看Object类中equal方法的实现，==比较的其实是两个对象在内存中的地址。
public boolean equals(Object obj) { return (this == obj); } 说起equals方法，就不得不说hashCode方法了。Java中对于hashCode有个常规协定
The general contract of hashCode is:</description></item><item><title>多线程下的单例模式+反汇编</title><link>https://atbug.com/articles/singleton-in-multi-threads-programming/</link><pubDate>Wed, 06 Jul 2016 16:57:09 +0000</pubDate><guid>https://atbug.com/articles/singleton-in-multi-threads-programming/</guid><description>多线程下的单例模式的实现，顺便做了反汇编。
public class MySingleton { private static MySingleton INSTANCE; private MySingleton() { } public static MySingleton getInstance() { if (INSTANCE == null) { synchronized (MySingleton.class) { INSTANCE = new MySingleton(); } } return INSTANCE; } } Compiled from &amp;#34;MySingleton.java&amp;#34; public class MySingleton { public static MySingleton getInstance(); Code: 0: getstatic #2 // Field INSTANCE:LMySingleton; //+获得类的指定域，并压入栈顶 3: ifnonnull 32 //+不为null时跳转到行号32 6: ldc_w #3 // class MySingleton //+常量值从常量池中推送至栈顶（宽索引），推送的为地址 9: dup //+复制栈顶数值，并且复制值进栈 10: astore_0 //+将栈顶数值（objectref）存入当前 frame的局部变量数组中指定下标(index）处的变量中，栈顶数值出栈。这里存的是MySingleton类定义的地址 11: monitorenter //+获得对象锁即MySingleton地址 12: new #3 // class MySingleton //+创建一个对象，并且其引用进栈 15: dup //+复制栈顶数值，并且复制值进栈 16: invokespecial #4 // Method &amp;#34;&amp;lt;init&amp;gt;&amp;#34;:()V //+调用超类构造方法、实例初始化方法、私有方法 19: putstatic #2 // Field INSTANCE:LMySingleton; //+为指定的类的静态域赋值 22: aload_0 //+当前frame的局部变量数组中下标为 index的引用型局部变量进栈，这里是MySingleton类定义的地址 23: monitorexit //+释放对象锁 24: goto 32 //+跳转到行号32 27: astore_1 //+将栈顶数值（objectref）存入当前 frame的局部变量数组中指定下标(index）处的变量中，栈顶数值出栈。 28: aload_0 //+当前frame的局部变量数组中下标为 0的引用型局部变量进栈 29: monitorexit //+//+释放对象锁 30: aload_1 //+当前frame的局部变量数组中下标为 1的引用型局部变量进栈 31: athrow //+将栈顶的数值作为异常或错误抛出 32: getstatic #2 // Field INSTANCE:LMySingleton; //+获得类的指定域，并压入栈顶 35: areturn //+从方法中返回一个对象的引用 Exception table: from to target type 12 24 27 any 27 30 27 any }</description></item><item><title>使用Kryo替换spring amqp的Java序列化</title><link>https://atbug.com/articles/use-kryo-in-spring-amqp-serialization/</link><pubDate>Wed, 29 Jun 2016 05:29:14 +0000</pubDate><guid>https://atbug.com/articles/use-kryo-in-spring-amqp-serialization/</guid><description>spring amqp的原生并没有对Kryo加以支持，Kryo的优点就不多说了。
git地址：https://github.com/addozhang/spring-kryo-messaeg-converter
public class KryoMessageConverter extends AbstractMessageConverter { public static final String CONTENT_TYPE = &amp;#34;application/x-kryo&amp;#34;; public static final String DEFAULT_CHARSET = &amp;#34;UTF-8&amp;#34;; private String defaultCharset = DEFAULT_CHARSET; private KryoFactory kryoFactory = new DefaultKryoFactory(); /** * Crate a message from the payload object and message properties provided.</description></item><item><title>关于SLF4J</title><link>https://atbug.com/articles/about-slf4j/</link><pubDate>Sat, 18 Apr 2015 11:16:26 +0000</pubDate><guid>https://atbug.com/articles/about-slf4j/</guid><description>Spring的功能越来越强大，同时也越来越臃肿。比如想快速搭建一个基于Spring的项目，解决依赖问题非常耗时。Spring的项目模板的出现就解决了这个问题，通过这个描述文件，可以快速的找到你所需要的模板。
第一次认识SLF4J就是在这些项目模板里，它的全称是Simple Logging Facade for Java。从字面上可以看出它只是一个Facade，不提供具体的日志解决方案，只服务于各个日志系统。简单说有了它，我们就可以随意的更换日志系统（如java.util.logging、logback、log4j）。比如在开发的时候使用logback，部署的时候可以切换到log4j；如果关闭所有的log，切换到NOP就可以了。只需要更改依赖，提供日志配置文件，免去了修改代码的麻烦。
首先看如何使用：
[java] import org.slf4j.Logger; import org.slf4j.LoggerFactory;
public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(&amp;quot;Hello World&amp;quot;); } } [/java]
SLF4J封装了使用起来和其他日志系统一样简单。上面提到过SLF4J不提供具体的日志解决方案，所以使用的时候除了要引用SLF4J包，还要引用具体的日志解决方案包（log4j、logging&amp;ndash;JDK提供、logback），还有所对应的binding包（slf4j-log4j_、slf4j-jdk14、logback-classic_）。
以log4j为例，我们看SLF4J的实现方式。
SLF4J类在初始化的时候会尝试从ClassLoader中org/slf4j/impl/StaticLoggerBinder.class。这个类比较特殊，每个binding包里都有。不同binding包里的StaticLoggerBinder类会去初始化一个相应的实例，如slf4j-log4j里：
[java] /**
截取的部分代码 */ private StaticLoggerBinder() { loggerFactory = new Log4jLoggerFactory(); } [/java] 而Log4jLoggerAdapter实现了SLF4J的Logger接口，使用了Adapter模式对Log4j的Logger进行了封装并暴露了Logger的接口，Log4jLoggerFactory持有了Log4jLoggerAdapter的实例。</description></item></channel></rss>