<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>eBPF on 乱世浮生</title><link>https://atbug.com/tags/ebpf/</link><description>Recent content in eBPF on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Wed, 11 Jan 2023 18:12:58 +0800</lastBuildDate><atom:link href="https://atbug.com/tags/ebpf/index.xml" rel="self" type="application/rss+xml"/><item><title>Kubernetes 网络学习之 Cilium 与 eBPF</title><link>https://atbug.com/learn-cilium-and-ebpf/</link><pubDate>Wed, 11 Jan 2023 18:12:58 +0800</pubDate><guid>https://atbug.com/learn-cilium-and-ebpf/</guid><description>这是 Kubernetes 网络学习的第五篇笔记，也是之前计划中的最后一篇。
深入探索 Kubernetes 网络模型和网络通信 认识一下容器网络接口 CNI 源码分析：从 kubelet、容器运行时看 CNI 的使用 从 Flannel 学习 Kubernetes VXLAN 网络 Kubernetes 网络学习之 Cilium 与 eBPF（本篇） &amp;hellip; 开始之前说点题外话，距离上一篇 Flannel CNI 的发布已经快一个月了。这篇本想趁着势头在去年底完成的，正好在一个月内完成计划的所有内容。但上篇发布后不久，我中招了花了一个多周的时间才恢复。然而，恢复后的状态让我有点懵，总感觉很难集中精力，很容易精神涣散。可能接近网上流传的“脑雾”吧，而且 Cilium 也有点类似一团迷雾。再叠加网络知识的不足，eBPF 也未从涉足，学习的过程中断断续续，我曾经一度怀疑这篇会不会流产。
文章中不免会有问题，如果有发现问题或者建议，望不吝赐教。
背景 去年曾经写过一篇文章 [《使用 Cilium 增强 Kubernetes 网络安全》](《使用 Cilium 增强 Kubernetes 网络安全》) 接触过 Cilium，借助 Cilium 的网络策略从网络层面对 pod 间的通信进行限制。但当时我不曾深入其实现原理，对 Kubernetes 网络和 CNI 的了解也不够深入。这次我们通过实际的环境来探寻 Cilium 的网络。</description></item><item><title>【译】eBPF 和服务网格：还不能丢掉 Sidecar</title><link>https://atbug.com/translate-ebpf-service-mesh/</link><pubDate>Mon, 31 Oct 2022 20:51:17 -0400</pubDate><guid>https://atbug.com/translate-ebpf-service-mesh/</guid><description>服务网格以典型的 sidecar 模型为人熟知，将 sidecar 容器与应用容器部署在同一个 Pod 中。虽说 sidecar 并非很新的模型（操作系统的 systemd、initd、cron 进程；Java 的多线程），但是以这种与业务逻辑分离的方式来提供服务治理等基础能力的设计还是让人一亮。
随着 eBPF 等技术的引入，最近关于服务网格是否需要 sidecar （也就是 sidecarless）的讨论渐增。
笔者认为任何问题都有其起因，长久困扰服务网格的不外乎性能和资源占用。这篇文章翻译自 Buoyant 的 Flynn 文章 eBPF and the Service Mesh: Don&amp;rsquo;t Dismiss the Sidecar Yet。希望这篇文章能帮助大家穿透迷雾看透事物的本质。
本文要点 eBPF 是一个旨在通过（谨慎地）允许在内核中运行一些用户代码来提高性能的工具。 在可预见的未来，服务网格所需的第 7 层处理在 eBPF 中不太可能实现，这意味着网格仍然需要代理。 与 sidecar 代理相比，每个主机代理增加了操作复杂性并降低了安全性。 可以通过更小、更快的 Sidecar 代理来解决有关 Sidecar 代理的典型性能问题。 目前，sidecar 模型对服务网格仍是最有意义的。 关于 eBPF 的故事已经在云原生世界中泛滥了一段时间，有时将其描述为自切片面包以来最伟大的事物，有时则嘲笑它是对现实世界的无用干扰。当然，现实要微妙得多，因此仔细研究一下 eBPF 能做什么和不能做什么似乎是有必要的——技术毕竟只是工具，使用的工具应该适合手头的任务。</description></item><item><title>使用 Cilium 增强 Kubernetes 网络安全</title><link>https://atbug.com/enhance-kubernetes-network-security-with-cilium/</link><pubDate>Sun, 13 Feb 2022 05:03:48 +0800</pubDate><guid>https://atbug.com/enhance-kubernetes-network-security-with-cilium/</guid><description>TL;DR 在本篇，我们分别使用了 Kubernetes 原生的网络策略和 Cilium 的网络策略实现了 Pod 网络层面的隔离。不同的是，前者只提供了基于 L3/4 的网络策略；后者支持 L3/4、L7 的网络策略。
通过网络策略来提升网络安全，可以极大降低了实现和维护的成本，同时对系统几乎没有影响。
尤其是基于 eBPF 技术的 Cilium，解决了内核扩展性不足的问题，从内核层面为工作负载提供安全可靠、可观测的网络连接。
目录 TL;DR 目录 背景 示例应用 Kubernetes 网络策略 测试 思考 Cilium 网络策略 Cilium 简介 测试 背景 为什么说 Kubernetes 网络存在安全隐患？集群中的 Pod 默认是未隔离的，也就是 Pod 之间的网络是互通的，可以互相通信的。</description></item><item><title>eBPF 和 Wasm：探索服务网格数据平面的未来</title><link>https://atbug.com/ebpf-wasm-service-mesh/</link><pubDate>Tue, 11 Jan 2022 10:40:56 +0800</pubDate><guid>https://atbug.com/ebpf-wasm-service-mesh/</guid><description>本文翻译自 Vivian Hu 的 《eBPF and Wasm: Exploring the Future of the Service Mesh Data Plane》。
在 2021 年 12 月 2 日，Cilium 项目宣布了 Cilium Service Mesh 项目的测试版。在 2020 年 8 月 Google Cloud 宣布基于 eBPF 的 Google Kubernetes 服务（GKS）的数据平面 V2 的一年后，Cilium Service Mesh 带来了 “无边车服务网格”（sidecarless service mesh）的想法。它扩展了 Cilium eBPF 产品来处理服务网格中的大部分边车代理功能，包括 7 层路由和负载均衡、TLS 终止、访问策略、健康检查、日志和跟踪，以及内置的 Kubernetes Ingress。</description></item></channel></rss>