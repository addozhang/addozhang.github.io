<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>一致性 on 乱世浮生</title><link>https://atbug.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7/</link><description>Recent content in 一致性 on 乱世浮生</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 26 Sep 2017 19:13:48 +0000</lastBuildDate><atom:link href="https://atbug.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7/index.xml" rel="self" type="application/rss+xml"/><item><title>Kafka消息消费一致性</title><link>https://atbug.com/articles/kafka-consumer-consistency/</link><pubDate>Tue, 26 Sep 2017 19:13:48 +0000</pubDate><guid>https://atbug.com/articles/kafka-consumer-consistency/</guid><description>Kafka消费端的offset主要由consumer来控制, Kafka降每个consumer所监听的tocpic的partition的offset保存在__consumer_offsets主题中. consumer需要将处理完成的消息的offset提交到服务端, 主要有ConsumerCoordinator完成的.
每次从kafka拉取数据之前, 假如是异步提交offset, 会先调用已经完成的offset commit的callBack, 然后检查ConsumerCoordinator的连接状态. 如果设置了自动提交offset, 会继续上次从服务端获取的数据的offset异步提交到服务端. 这里需要注意的是会有几种情况出现:
消息处理耗时较多, 假如处理单条消息的耗时为t, 拉取的消息个数为n. t * n &amp;gt; auto_commit_interval_ms, 会导致没有处理完的消息的offset被commit到服务端. 假如此时消费端挂掉, 没有处理完的数据将会丢失. 假如消息处理完成, offset还未commit到服务端的时候消费端挂掉, 已经处理完的消息会被再次消费. 下面配置影响着数据一致性和性能, 因此需要结合业务场景合理配置一下参数, 进行取舍.
enable.auto.commit 默认为true
auto.commit.interval.ms 默认为5000 ms (5s)</description></item></channel></rss>